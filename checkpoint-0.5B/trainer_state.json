{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 37365,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006690753378830456,
      "grad_norm": 1.2094544172286987,
      "learning_rate": 0.00019975913287836213,
      "loss": 1.249,
      "step": 50
    },
    {
      "epoch": 0.013381506757660913,
      "grad_norm": 1.0975964069366455,
      "learning_rate": 0.0001994915027432089,
      "loss": 0.5543,
      "step": 100
    },
    {
      "epoch": 0.02007226013649137,
      "grad_norm": 1.1872612237930298,
      "learning_rate": 0.0001992238726080557,
      "loss": 0.4946,
      "step": 150
    },
    {
      "epoch": 0.026763013515321826,
      "grad_norm": 0.617920994758606,
      "learning_rate": 0.00019895624247290246,
      "loss": 0.5072,
      "step": 200
    },
    {
      "epoch": 0.03345376689415228,
      "grad_norm": 0.4969979226589203,
      "learning_rate": 0.00019868861233774925,
      "loss": 0.4285,
      "step": 250
    },
    {
      "epoch": 0.04014452027298274,
      "grad_norm": 0.7501699328422546,
      "learning_rate": 0.00019842098220259602,
      "loss": 0.4361,
      "step": 300
    },
    {
      "epoch": 0.0468352736518132,
      "grad_norm": 0.5528366565704346,
      "learning_rate": 0.0001981533520674428,
      "loss": 0.417,
      "step": 350
    },
    {
      "epoch": 0.05352602703064365,
      "grad_norm": 0.587406575679779,
      "learning_rate": 0.00019788572193228958,
      "loss": 0.4348,
      "step": 400
    },
    {
      "epoch": 0.060216780409474105,
      "grad_norm": 0.8361437320709229,
      "learning_rate": 0.00019761809179713637,
      "loss": 0.3915,
      "step": 450
    },
    {
      "epoch": 0.06690753378830457,
      "grad_norm": 0.815803050994873,
      "learning_rate": 0.00019735046166198314,
      "loss": 0.4346,
      "step": 500
    },
    {
      "epoch": 0.07359828716713501,
      "grad_norm": 0.8272759318351746,
      "learning_rate": 0.00019708283152682993,
      "loss": 0.3716,
      "step": 550
    },
    {
      "epoch": 0.08028904054596547,
      "grad_norm": 1.2067737579345703,
      "learning_rate": 0.0001968152013916767,
      "loss": 0.446,
      "step": 600
    },
    {
      "epoch": 0.08697979392479593,
      "grad_norm": 0.7655658721923828,
      "learning_rate": 0.0001965475712565235,
      "loss": 0.4102,
      "step": 650
    },
    {
      "epoch": 0.0936705473036264,
      "grad_norm": 1.5312368869781494,
      "learning_rate": 0.00019627994112137026,
      "loss": 0.4255,
      "step": 700
    },
    {
      "epoch": 0.10036130068245684,
      "grad_norm": 0.216520756483078,
      "learning_rate": 0.00019601231098621705,
      "loss": 0.3797,
      "step": 750
    },
    {
      "epoch": 0.1070520540612873,
      "grad_norm": 0.4391818940639496,
      "learning_rate": 0.00019574468085106384,
      "loss": 0.3746,
      "step": 800
    },
    {
      "epoch": 0.11374280744011776,
      "grad_norm": 0.9772990942001343,
      "learning_rate": 0.00019547705071591064,
      "loss": 0.4509,
      "step": 850
    },
    {
      "epoch": 0.12043356081894821,
      "grad_norm": 0.2676212787628174,
      "learning_rate": 0.0001952094205807574,
      "loss": 0.4225,
      "step": 900
    },
    {
      "epoch": 0.12712431419777867,
      "grad_norm": 1.3993138074874878,
      "learning_rate": 0.0001949417904456042,
      "loss": 0.3813,
      "step": 950
    },
    {
      "epoch": 0.13381506757660913,
      "grad_norm": 0.3170156180858612,
      "learning_rate": 0.00019467416031045096,
      "loss": 0.384,
      "step": 1000
    },
    {
      "epoch": 0.1405058209554396,
      "grad_norm": 0.8557090759277344,
      "learning_rate": 0.00019440653017529776,
      "loss": 0.4398,
      "step": 1050
    },
    {
      "epoch": 0.14719657433427003,
      "grad_norm": 0.7246402502059937,
      "learning_rate": 0.00019413890004014452,
      "loss": 0.4449,
      "step": 1100
    },
    {
      "epoch": 0.15388732771310049,
      "grad_norm": 0.28380128741264343,
      "learning_rate": 0.00019387126990499132,
      "loss": 0.4026,
      "step": 1150
    },
    {
      "epoch": 0.16057808109193095,
      "grad_norm": 0.44018152356147766,
      "learning_rate": 0.00019360363976983808,
      "loss": 0.4045,
      "step": 1200
    },
    {
      "epoch": 0.1672688344707614,
      "grad_norm": 0.43134933710098267,
      "learning_rate": 0.00019333600963468488,
      "loss": 0.4249,
      "step": 1250
    },
    {
      "epoch": 0.17395958784959187,
      "grad_norm": 0.5322417616844177,
      "learning_rate": 0.00019306837949953164,
      "loss": 0.4196,
      "step": 1300
    },
    {
      "epoch": 0.18065034122842233,
      "grad_norm": 0.44791746139526367,
      "learning_rate": 0.00019280074936437844,
      "loss": 0.4438,
      "step": 1350
    },
    {
      "epoch": 0.1873410946072528,
      "grad_norm": 0.35913193225860596,
      "learning_rate": 0.0001925331192292252,
      "loss": 0.4289,
      "step": 1400
    },
    {
      "epoch": 0.19403184798608322,
      "grad_norm": 0.3723679184913635,
      "learning_rate": 0.000192265489094072,
      "loss": 0.3928,
      "step": 1450
    },
    {
      "epoch": 0.20072260136491368,
      "grad_norm": 0.44869929552078247,
      "learning_rate": 0.0001919978589589188,
      "loss": 0.3886,
      "step": 1500
    },
    {
      "epoch": 0.20741335474374414,
      "grad_norm": 0.8467375636100769,
      "learning_rate": 0.00019173022882376555,
      "loss": 0.396,
      "step": 1550
    },
    {
      "epoch": 0.2141041081225746,
      "grad_norm": 0.1983242928981781,
      "learning_rate": 0.00019146259868861235,
      "loss": 0.3912,
      "step": 1600
    },
    {
      "epoch": 0.22079486150140507,
      "grad_norm": 0.26350000500679016,
      "learning_rate": 0.00019119496855345914,
      "loss": 0.4084,
      "step": 1650
    },
    {
      "epoch": 0.22748561488023553,
      "grad_norm": 0.9483891129493713,
      "learning_rate": 0.0001909273384183059,
      "loss": 0.41,
      "step": 1700
    },
    {
      "epoch": 0.23417636825906596,
      "grad_norm": 0.32804161310195923,
      "learning_rate": 0.0001906597082831527,
      "loss": 0.4145,
      "step": 1750
    },
    {
      "epoch": 0.24086712163789642,
      "grad_norm": 0.3529583215713501,
      "learning_rate": 0.00019039207814799947,
      "loss": 0.4175,
      "step": 1800
    },
    {
      "epoch": 0.24755787501672688,
      "grad_norm": 0.9704822897911072,
      "learning_rate": 0.00019012444801284626,
      "loss": 0.4064,
      "step": 1850
    },
    {
      "epoch": 0.25424862839555734,
      "grad_norm": 0.9674893617630005,
      "learning_rate": 0.00018985681787769303,
      "loss": 0.4331,
      "step": 1900
    },
    {
      "epoch": 0.2609393817743878,
      "grad_norm": 0.8652519583702087,
      "learning_rate": 0.00018958918774253982,
      "loss": 0.3723,
      "step": 1950
    },
    {
      "epoch": 0.26763013515321826,
      "grad_norm": 0.1859244406223297,
      "learning_rate": 0.0001893215576073866,
      "loss": 0.4003,
      "step": 2000
    },
    {
      "epoch": 0.2743208885320487,
      "grad_norm": 0.2564353346824646,
      "learning_rate": 0.00018905392747223338,
      "loss": 0.3708,
      "step": 2050
    },
    {
      "epoch": 0.2810116419108792,
      "grad_norm": 0.5741984248161316,
      "learning_rate": 0.00018878629733708015,
      "loss": 0.3772,
      "step": 2100
    },
    {
      "epoch": 0.28770239528970964,
      "grad_norm": 0.883870542049408,
      "learning_rate": 0.00018851866720192694,
      "loss": 0.401,
      "step": 2150
    },
    {
      "epoch": 0.29439314866854005,
      "grad_norm": 1.1450921297073364,
      "learning_rate": 0.0001882510370667737,
      "loss": 0.406,
      "step": 2200
    },
    {
      "epoch": 0.3010839020473705,
      "grad_norm": 0.49304598569869995,
      "learning_rate": 0.0001879834069316205,
      "loss": 0.4051,
      "step": 2250
    },
    {
      "epoch": 0.30777465542620097,
      "grad_norm": 0.646501898765564,
      "learning_rate": 0.0001877157767964673,
      "loss": 0.4312,
      "step": 2300
    },
    {
      "epoch": 0.31446540880503143,
      "grad_norm": 0.869455873966217,
      "learning_rate": 0.00018744814666131406,
      "loss": 0.4337,
      "step": 2350
    },
    {
      "epoch": 0.3211561621838619,
      "grad_norm": 0.2645808756351471,
      "learning_rate": 0.00018718051652616085,
      "loss": 0.3935,
      "step": 2400
    },
    {
      "epoch": 0.32784691556269235,
      "grad_norm": 0.6104367971420288,
      "learning_rate": 0.00018691288639100765,
      "loss": 0.4378,
      "step": 2450
    },
    {
      "epoch": 0.3345376689415228,
      "grad_norm": 0.24189646542072296,
      "learning_rate": 0.00018664525625585444,
      "loss": 0.4057,
      "step": 2500
    },
    {
      "epoch": 0.3412284223203533,
      "grad_norm": 0.2340329885482788,
      "learning_rate": 0.0001863776261207012,
      "loss": 0.4269,
      "step": 2550
    },
    {
      "epoch": 0.34791917569918374,
      "grad_norm": 0.17951492965221405,
      "learning_rate": 0.000186109995985548,
      "loss": 0.4245,
      "step": 2600
    },
    {
      "epoch": 0.3546099290780142,
      "grad_norm": 0.913782000541687,
      "learning_rate": 0.00018584236585039477,
      "loss": 0.4431,
      "step": 2650
    },
    {
      "epoch": 0.36130068245684466,
      "grad_norm": 0.4712468981742859,
      "learning_rate": 0.00018557473571524156,
      "loss": 0.4034,
      "step": 2700
    },
    {
      "epoch": 0.3679914358356751,
      "grad_norm": 0.8885096311569214,
      "learning_rate": 0.00018530710558008833,
      "loss": 0.435,
      "step": 2750
    },
    {
      "epoch": 0.3746821892145056,
      "grad_norm": 0.44207125902175903,
      "learning_rate": 0.00018503947544493512,
      "loss": 0.4361,
      "step": 2800
    },
    {
      "epoch": 0.381372942593336,
      "grad_norm": 1.5828112363815308,
      "learning_rate": 0.00018477184530978189,
      "loss": 0.4012,
      "step": 2850
    },
    {
      "epoch": 0.38806369597216644,
      "grad_norm": 0.48564112186431885,
      "learning_rate": 0.00018450421517462868,
      "loss": 0.418,
      "step": 2900
    },
    {
      "epoch": 0.3947544493509969,
      "grad_norm": 1.1941115856170654,
      "learning_rate": 0.00018423658503947544,
      "loss": 0.4009,
      "step": 2950
    },
    {
      "epoch": 0.40144520272982737,
      "grad_norm": 0.755866527557373,
      "learning_rate": 0.00018396895490432224,
      "loss": 0.4038,
      "step": 3000
    },
    {
      "epoch": 0.4081359561086578,
      "grad_norm": 1.2739052772521973,
      "learning_rate": 0.000183701324769169,
      "loss": 0.4175,
      "step": 3050
    },
    {
      "epoch": 0.4148267094874883,
      "grad_norm": 0.38699766993522644,
      "learning_rate": 0.0001834336946340158,
      "loss": 0.3843,
      "step": 3100
    },
    {
      "epoch": 0.42151746286631875,
      "grad_norm": 1.5816689729690552,
      "learning_rate": 0.00018316606449886256,
      "loss": 0.3945,
      "step": 3150
    },
    {
      "epoch": 0.4282082162451492,
      "grad_norm": 0.5679981708526611,
      "learning_rate": 0.00018289843436370936,
      "loss": 0.408,
      "step": 3200
    },
    {
      "epoch": 0.43489896962397967,
      "grad_norm": 0.7555642127990723,
      "learning_rate": 0.00018263080422855615,
      "loss": 0.3859,
      "step": 3250
    },
    {
      "epoch": 0.44158972300281013,
      "grad_norm": 0.3477109372615814,
      "learning_rate": 0.00018236317409340294,
      "loss": 0.3818,
      "step": 3300
    },
    {
      "epoch": 0.4482804763816406,
      "grad_norm": 0.3313606381416321,
      "learning_rate": 0.0001820955439582497,
      "loss": 0.4492,
      "step": 3350
    },
    {
      "epoch": 0.45497122976047105,
      "grad_norm": 0.6235567331314087,
      "learning_rate": 0.0001818279138230965,
      "loss": 0.3707,
      "step": 3400
    },
    {
      "epoch": 0.4616619831393015,
      "grad_norm": 0.17287997901439667,
      "learning_rate": 0.00018156028368794327,
      "loss": 0.442,
      "step": 3450
    },
    {
      "epoch": 0.4683527365181319,
      "grad_norm": 0.8089641332626343,
      "learning_rate": 0.00018129265355279006,
      "loss": 0.3857,
      "step": 3500
    },
    {
      "epoch": 0.4750434898969624,
      "grad_norm": 0.27111417055130005,
      "learning_rate": 0.00018102502341763683,
      "loss": 0.3939,
      "step": 3550
    },
    {
      "epoch": 0.48173424327579284,
      "grad_norm": 0.4577833116054535,
      "learning_rate": 0.00018075739328248362,
      "loss": 0.3951,
      "step": 3600
    },
    {
      "epoch": 0.4884249966546233,
      "grad_norm": 0.4060816764831543,
      "learning_rate": 0.0001804897631473304,
      "loss": 0.4034,
      "step": 3650
    },
    {
      "epoch": 0.49511575003345376,
      "grad_norm": 0.4818997383117676,
      "learning_rate": 0.00018022213301217718,
      "loss": 0.4032,
      "step": 3700
    },
    {
      "epoch": 0.5018065034122843,
      "grad_norm": 0.34853342175483704,
      "learning_rate": 0.00017995450287702395,
      "loss": 0.3967,
      "step": 3750
    },
    {
      "epoch": 0.5084972567911147,
      "grad_norm": 0.2232893705368042,
      "learning_rate": 0.00017968687274187074,
      "loss": 0.4227,
      "step": 3800
    },
    {
      "epoch": 0.5151880101699451,
      "grad_norm": 1.1984342336654663,
      "learning_rate": 0.0001794192426067175,
      "loss": 0.4058,
      "step": 3850
    },
    {
      "epoch": 0.5218787635487756,
      "grad_norm": 0.6056904196739197,
      "learning_rate": 0.0001791516124715643,
      "loss": 0.3728,
      "step": 3900
    },
    {
      "epoch": 0.528569516927606,
      "grad_norm": 2.042168617248535,
      "learning_rate": 0.00017888398233641107,
      "loss": 0.4307,
      "step": 3950
    },
    {
      "epoch": 0.5352602703064365,
      "grad_norm": 1.0989127159118652,
      "learning_rate": 0.00017861635220125786,
      "loss": 0.4306,
      "step": 4000
    },
    {
      "epoch": 0.5419510236852669,
      "grad_norm": 0.21461620926856995,
      "learning_rate": 0.00017834872206610466,
      "loss": 0.4122,
      "step": 4050
    },
    {
      "epoch": 0.5486417770640974,
      "grad_norm": 0.14973415434360504,
      "learning_rate": 0.00017808109193095145,
      "loss": 0.4243,
      "step": 4100
    },
    {
      "epoch": 0.5553325304429279,
      "grad_norm": 0.22295168042182922,
      "learning_rate": 0.00017781346179579822,
      "loss": 0.3822,
      "step": 4150
    },
    {
      "epoch": 0.5620232838217584,
      "grad_norm": 0.4010312557220459,
      "learning_rate": 0.000177545831660645,
      "loss": 0.3836,
      "step": 4200
    },
    {
      "epoch": 0.5687140372005888,
      "grad_norm": 1.0222787857055664,
      "learning_rate": 0.00017727820152549178,
      "loss": 0.3892,
      "step": 4250
    },
    {
      "epoch": 0.5754047905794193,
      "grad_norm": 0.4695068597793579,
      "learning_rate": 0.00017701057139033857,
      "loss": 0.4439,
      "step": 4300
    },
    {
      "epoch": 0.5820955439582497,
      "grad_norm": 0.6212395429611206,
      "learning_rate": 0.00017674294125518534,
      "loss": 0.3966,
      "step": 4350
    },
    {
      "epoch": 0.5887862973370801,
      "grad_norm": 0.23289170861244202,
      "learning_rate": 0.00017647531112003213,
      "loss": 0.4236,
      "step": 4400
    },
    {
      "epoch": 0.5954770507159106,
      "grad_norm": 1.069625735282898,
      "learning_rate": 0.0001762076809848789,
      "loss": 0.4237,
      "step": 4450
    },
    {
      "epoch": 0.602167804094741,
      "grad_norm": 1.0584485530853271,
      "learning_rate": 0.0001759400508497257,
      "loss": 0.3857,
      "step": 4500
    },
    {
      "epoch": 0.6088585574735715,
      "grad_norm": 0.4552777111530304,
      "learning_rate": 0.00017567242071457245,
      "loss": 0.3642,
      "step": 4550
    },
    {
      "epoch": 0.6155493108524019,
      "grad_norm": 0.5088470578193665,
      "learning_rate": 0.00017540479057941925,
      "loss": 0.3978,
      "step": 4600
    },
    {
      "epoch": 0.6222400642312325,
      "grad_norm": 0.426977276802063,
      "learning_rate": 0.00017513716044426601,
      "loss": 0.4051,
      "step": 4650
    },
    {
      "epoch": 0.6289308176100629,
      "grad_norm": 0.34895673394203186,
      "learning_rate": 0.0001748695303091128,
      "loss": 0.3754,
      "step": 4700
    },
    {
      "epoch": 0.6356215709888934,
      "grad_norm": 0.8875690698623657,
      "learning_rate": 0.00017460190017395957,
      "loss": 0.3961,
      "step": 4750
    },
    {
      "epoch": 0.6423123243677238,
      "grad_norm": 0.22058899700641632,
      "learning_rate": 0.00017433427003880637,
      "loss": 0.3865,
      "step": 4800
    },
    {
      "epoch": 0.6490030777465543,
      "grad_norm": 1.675205111503601,
      "learning_rate": 0.00017406663990365316,
      "loss": 0.3796,
      "step": 4850
    },
    {
      "epoch": 0.6556938311253847,
      "grad_norm": 0.4143179953098297,
      "learning_rate": 0.00017379900976849995,
      "loss": 0.4192,
      "step": 4900
    },
    {
      "epoch": 0.6623845845042152,
      "grad_norm": 1.1972105503082275,
      "learning_rate": 0.00017353137963334672,
      "loss": 0.3996,
      "step": 4950
    },
    {
      "epoch": 0.6690753378830456,
      "grad_norm": 0.3344920575618744,
      "learning_rate": 0.00017326374949819351,
      "loss": 0.3929,
      "step": 5000
    },
    {
      "epoch": 0.675766091261876,
      "grad_norm": 0.25875920057296753,
      "learning_rate": 0.00017299611936304028,
      "loss": 0.428,
      "step": 5050
    },
    {
      "epoch": 0.6824568446407066,
      "grad_norm": 0.23330949246883392,
      "learning_rate": 0.00017272848922788707,
      "loss": 0.4223,
      "step": 5100
    },
    {
      "epoch": 0.689147598019537,
      "grad_norm": 0.8038330674171448,
      "learning_rate": 0.00017246085909273384,
      "loss": 0.4558,
      "step": 5150
    },
    {
      "epoch": 0.6958383513983675,
      "grad_norm": 0.5264343619346619,
      "learning_rate": 0.00017219322895758063,
      "loss": 0.4078,
      "step": 5200
    },
    {
      "epoch": 0.7025291047771979,
      "grad_norm": 0.4672664701938629,
      "learning_rate": 0.0001719255988224274,
      "loss": 0.4576,
      "step": 5250
    },
    {
      "epoch": 0.7092198581560284,
      "grad_norm": 0.8671495914459229,
      "learning_rate": 0.0001716579686872742,
      "loss": 0.4134,
      "step": 5300
    },
    {
      "epoch": 0.7159106115348588,
      "grad_norm": 0.4816766083240509,
      "learning_rate": 0.00017139033855212099,
      "loss": 0.4161,
      "step": 5350
    },
    {
      "epoch": 0.7226013649136893,
      "grad_norm": 0.40617305040359497,
      "learning_rate": 0.00017112270841696775,
      "loss": 0.3936,
      "step": 5400
    },
    {
      "epoch": 0.7292921182925197,
      "grad_norm": 1.3538552522659302,
      "learning_rate": 0.00017085507828181455,
      "loss": 0.4284,
      "step": 5450
    },
    {
      "epoch": 0.7359828716713502,
      "grad_norm": 0.3460617661476135,
      "learning_rate": 0.0001705874481466613,
      "loss": 0.4282,
      "step": 5500
    },
    {
      "epoch": 0.7426736250501806,
      "grad_norm": 0.7711225748062134,
      "learning_rate": 0.0001703198180115081,
      "loss": 0.3833,
      "step": 5550
    },
    {
      "epoch": 0.7493643784290112,
      "grad_norm": 0.512188196182251,
      "learning_rate": 0.00017005218787635487,
      "loss": 0.4126,
      "step": 5600
    },
    {
      "epoch": 0.7560551318078416,
      "grad_norm": 0.9336113333702087,
      "learning_rate": 0.00016978455774120167,
      "loss": 0.3706,
      "step": 5650
    },
    {
      "epoch": 0.762745885186672,
      "grad_norm": 1.0185229778289795,
      "learning_rate": 0.00016951692760604846,
      "loss": 0.4287,
      "step": 5700
    },
    {
      "epoch": 0.7694366385655025,
      "grad_norm": 0.3901091516017914,
      "learning_rate": 0.00016924929747089525,
      "loss": 0.3828,
      "step": 5750
    },
    {
      "epoch": 0.7761273919443329,
      "grad_norm": 0.4252051115036011,
      "learning_rate": 0.00016898166733574202,
      "loss": 0.3881,
      "step": 5800
    },
    {
      "epoch": 0.7828181453231634,
      "grad_norm": 0.3947407603263855,
      "learning_rate": 0.0001687140372005888,
      "loss": 0.3997,
      "step": 5850
    },
    {
      "epoch": 0.7895088987019938,
      "grad_norm": 0.4769209325313568,
      "learning_rate": 0.00016844640706543558,
      "loss": 0.4096,
      "step": 5900
    },
    {
      "epoch": 0.7961996520808243,
      "grad_norm": 0.7719531655311584,
      "learning_rate": 0.00016817877693028237,
      "loss": 0.4103,
      "step": 5950
    },
    {
      "epoch": 0.8028904054596547,
      "grad_norm": 1.5071218013763428,
      "learning_rate": 0.00016791114679512914,
      "loss": 0.3907,
      "step": 6000
    },
    {
      "epoch": 0.8095811588384852,
      "grad_norm": 0.6466620564460754,
      "learning_rate": 0.00016764351665997593,
      "loss": 0.3873,
      "step": 6050
    },
    {
      "epoch": 0.8162719122173157,
      "grad_norm": 0.7575037479400635,
      "learning_rate": 0.00016738123912752578,
      "loss": 0.4091,
      "step": 6100
    },
    {
      "epoch": 0.8229626655961462,
      "grad_norm": 0.6858816146850586,
      "learning_rate": 0.00016711360899237255,
      "loss": 0.3867,
      "step": 6150
    },
    {
      "epoch": 0.8296534189749766,
      "grad_norm": 0.756560742855072,
      "learning_rate": 0.00016684597885721934,
      "loss": 0.3943,
      "step": 6200
    },
    {
      "epoch": 0.8363441723538071,
      "grad_norm": 0.37772244215011597,
      "learning_rate": 0.0001665783487220661,
      "loss": 0.4095,
      "step": 6250
    },
    {
      "epoch": 0.8430349257326375,
      "grad_norm": 0.6395037770271301,
      "learning_rate": 0.0001663107185869129,
      "loss": 0.4489,
      "step": 6300
    },
    {
      "epoch": 0.8497256791114679,
      "grad_norm": 0.9394850134849548,
      "learning_rate": 0.00016604308845175967,
      "loss": 0.4275,
      "step": 6350
    },
    {
      "epoch": 0.8564164324902984,
      "grad_norm": 0.21793009340763092,
      "learning_rate": 0.00016577545831660646,
      "loss": 0.4041,
      "step": 6400
    },
    {
      "epoch": 0.8631071858691288,
      "grad_norm": 0.34228286147117615,
      "learning_rate": 0.00016550782818145325,
      "loss": 0.3938,
      "step": 6450
    },
    {
      "epoch": 0.8697979392479593,
      "grad_norm": 0.9514709711074829,
      "learning_rate": 0.00016524019804630002,
      "loss": 0.3744,
      "step": 6500
    },
    {
      "epoch": 0.8764886926267897,
      "grad_norm": 0.22953614592552185,
      "learning_rate": 0.0001649725679111468,
      "loss": 0.3802,
      "step": 6550
    },
    {
      "epoch": 0.8831794460056203,
      "grad_norm": 0.40893587470054626,
      "learning_rate": 0.00016470493777599358,
      "loss": 0.4202,
      "step": 6600
    },
    {
      "epoch": 0.8898701993844507,
      "grad_norm": 0.36864811182022095,
      "learning_rate": 0.00016443730764084037,
      "loss": 0.3802,
      "step": 6650
    },
    {
      "epoch": 0.8965609527632812,
      "grad_norm": 0.3959944546222687,
      "learning_rate": 0.00016416967750568714,
      "loss": 0.4383,
      "step": 6700
    },
    {
      "epoch": 0.9032517061421116,
      "grad_norm": 0.6951000690460205,
      "learning_rate": 0.00016390204737053393,
      "loss": 0.4124,
      "step": 6750
    },
    {
      "epoch": 0.9099424595209421,
      "grad_norm": 0.3137010335922241,
      "learning_rate": 0.0001636344172353807,
      "loss": 0.3733,
      "step": 6800
    },
    {
      "epoch": 0.9166332128997725,
      "grad_norm": 0.18332137167453766,
      "learning_rate": 0.0001633667871002275,
      "loss": 0.4327,
      "step": 6850
    },
    {
      "epoch": 0.923323966278603,
      "grad_norm": 0.6107303500175476,
      "learning_rate": 0.00016309915696507428,
      "loss": 0.3777,
      "step": 6900
    },
    {
      "epoch": 0.9300147196574334,
      "grad_norm": 1.3166029453277588,
      "learning_rate": 0.00016283152682992108,
      "loss": 0.4131,
      "step": 6950
    },
    {
      "epoch": 0.9367054730362638,
      "grad_norm": 0.5353817939758301,
      "learning_rate": 0.00016256389669476784,
      "loss": 0.4189,
      "step": 7000
    },
    {
      "epoch": 0.9433962264150944,
      "grad_norm": 0.19899120926856995,
      "learning_rate": 0.00016229626655961464,
      "loss": 0.4094,
      "step": 7050
    },
    {
      "epoch": 0.9500869797939248,
      "grad_norm": 0.5547370910644531,
      "learning_rate": 0.0001620286364244614,
      "loss": 0.3696,
      "step": 7100
    },
    {
      "epoch": 0.9567777331727553,
      "grad_norm": 0.4701428711414337,
      "learning_rate": 0.0001617610062893082,
      "loss": 0.3957,
      "step": 7150
    },
    {
      "epoch": 0.9634684865515857,
      "grad_norm": 2.927459716796875,
      "learning_rate": 0.00016149337615415496,
      "loss": 0.4425,
      "step": 7200
    },
    {
      "epoch": 0.9701592399304162,
      "grad_norm": 0.3438909649848938,
      "learning_rate": 0.00016122574601900176,
      "loss": 0.4396,
      "step": 7250
    },
    {
      "epoch": 0.9768499933092466,
      "grad_norm": 0.7481973767280579,
      "learning_rate": 0.00016095811588384852,
      "loss": 0.4045,
      "step": 7300
    },
    {
      "epoch": 0.9835407466880771,
      "grad_norm": 0.27070894837379456,
      "learning_rate": 0.00016069048574869532,
      "loss": 0.41,
      "step": 7350
    },
    {
      "epoch": 0.9902315000669075,
      "grad_norm": 1.096035122871399,
      "learning_rate": 0.00016042285561354208,
      "loss": 0.4275,
      "step": 7400
    },
    {
      "epoch": 0.996922253445738,
      "grad_norm": 0.2713853716850281,
      "learning_rate": 0.00016015522547838888,
      "loss": 0.3561,
      "step": 7450
    },
    {
      "epoch": 1.0036130068245686,
      "grad_norm": 0.6254119873046875,
      "learning_rate": 0.00015988759534323564,
      "loss": 0.4191,
      "step": 7500
    },
    {
      "epoch": 1.0103037602033988,
      "grad_norm": 0.25145459175109863,
      "learning_rate": 0.00015961996520808244,
      "loss": 0.3726,
      "step": 7550
    },
    {
      "epoch": 1.0169945135822294,
      "grad_norm": 0.28272226452827454,
      "learning_rate": 0.0001593523350729292,
      "loss": 0.3615,
      "step": 7600
    },
    {
      "epoch": 1.0236852669610599,
      "grad_norm": 0.7801522016525269,
      "learning_rate": 0.000159084704937776,
      "loss": 0.4132,
      "step": 7650
    },
    {
      "epoch": 1.0303760203398902,
      "grad_norm": 0.3351019620895386,
      "learning_rate": 0.0001588170748026228,
      "loss": 0.373,
      "step": 7700
    },
    {
      "epoch": 1.0370667737187207,
      "grad_norm": 0.17291806638240814,
      "learning_rate": 0.00015854944466746958,
      "loss": 0.3496,
      "step": 7750
    },
    {
      "epoch": 1.0437575270975512,
      "grad_norm": 0.6036646366119385,
      "learning_rate": 0.00015828181453231635,
      "loss": 0.3717,
      "step": 7800
    },
    {
      "epoch": 1.0504482804763817,
      "grad_norm": 0.8148916959762573,
      "learning_rate": 0.00015801418439716314,
      "loss": 0.3752,
      "step": 7850
    },
    {
      "epoch": 1.057139033855212,
      "grad_norm": 1.0193533897399902,
      "learning_rate": 0.0001577465542620099,
      "loss": 0.3944,
      "step": 7900
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 0.94980788230896,
      "learning_rate": 0.0001574789241268567,
      "loss": 0.3895,
      "step": 7950
    },
    {
      "epoch": 1.070520540612873,
      "grad_norm": 0.2926246225833893,
      "learning_rate": 0.00015721129399170347,
      "loss": 0.364,
      "step": 8000
    },
    {
      "epoch": 1.0772112939917036,
      "grad_norm": 1.094242811203003,
      "learning_rate": 0.00015694366385655026,
      "loss": 0.3616,
      "step": 8050
    },
    {
      "epoch": 1.0839020473705339,
      "grad_norm": 0.5603488683700562,
      "learning_rate": 0.00015667603372139703,
      "loss": 0.3671,
      "step": 8100
    },
    {
      "epoch": 1.0905928007493644,
      "grad_norm": 0.5186992287635803,
      "learning_rate": 0.00015640840358624382,
      "loss": 0.3982,
      "step": 8150
    },
    {
      "epoch": 1.097283554128195,
      "grad_norm": 0.2903740108013153,
      "learning_rate": 0.0001561407734510906,
      "loss": 0.362,
      "step": 8200
    },
    {
      "epoch": 1.1039743075070252,
      "grad_norm": 0.27340662479400635,
      "learning_rate": 0.00015587314331593738,
      "loss": 0.3583,
      "step": 8250
    },
    {
      "epoch": 1.1106650608858557,
      "grad_norm": 1.2545231580734253,
      "learning_rate": 0.00015560551318078415,
      "loss": 0.3737,
      "step": 8300
    },
    {
      "epoch": 1.1173558142646862,
      "grad_norm": 1.1816158294677734,
      "learning_rate": 0.00015533788304563094,
      "loss": 0.3645,
      "step": 8350
    },
    {
      "epoch": 1.1240465676435167,
      "grad_norm": 0.2803645730018616,
      "learning_rate": 0.0001550702529104777,
      "loss": 0.3935,
      "step": 8400
    },
    {
      "epoch": 1.130737321022347,
      "grad_norm": 1.1197878122329712,
      "learning_rate": 0.0001548026227753245,
      "loss": 0.3524,
      "step": 8450
    },
    {
      "epoch": 1.1374280744011775,
      "grad_norm": 0.6301503777503967,
      "learning_rate": 0.0001545349926401713,
      "loss": 0.3825,
      "step": 8500
    },
    {
      "epoch": 1.144118827780008,
      "grad_norm": 1.15070378780365,
      "learning_rate": 0.0001542673625050181,
      "loss": 0.362,
      "step": 8550
    },
    {
      "epoch": 1.1508095811588386,
      "grad_norm": 1.1462452411651611,
      "learning_rate": 0.00015399973236986485,
      "loss": 0.4049,
      "step": 8600
    },
    {
      "epoch": 1.1575003345376689,
      "grad_norm": 0.34747713804244995,
      "learning_rate": 0.00015373210223471165,
      "loss": 0.369,
      "step": 8650
    },
    {
      "epoch": 1.1641910879164994,
      "grad_norm": 0.8226557970046997,
      "learning_rate": 0.00015346447209955841,
      "loss": 0.3758,
      "step": 8700
    },
    {
      "epoch": 1.17088184129533,
      "grad_norm": 0.5102173089981079,
      "learning_rate": 0.0001531968419644052,
      "loss": 0.4149,
      "step": 8750
    },
    {
      "epoch": 1.1775725946741602,
      "grad_norm": 0.20203405618667603,
      "learning_rate": 0.00015292921182925197,
      "loss": 0.3918,
      "step": 8800
    },
    {
      "epoch": 1.1842633480529907,
      "grad_norm": 0.39742040634155273,
      "learning_rate": 0.00015266158169409877,
      "loss": 0.3714,
      "step": 8850
    },
    {
      "epoch": 1.1909541014318212,
      "grad_norm": 0.8133169412612915,
      "learning_rate": 0.00015239395155894553,
      "loss": 0.367,
      "step": 8900
    },
    {
      "epoch": 1.1976448548106517,
      "grad_norm": 0.27009743452072144,
      "learning_rate": 0.00015212632142379233,
      "loss": 0.378,
      "step": 8950
    },
    {
      "epoch": 1.204335608189482,
      "grad_norm": 0.8796590566635132,
      "learning_rate": 0.0001518586912886391,
      "loss": 0.4061,
      "step": 9000
    },
    {
      "epoch": 1.2110263615683126,
      "grad_norm": 0.21463853120803833,
      "learning_rate": 0.00015159106115348589,
      "loss": 0.3488,
      "step": 9050
    },
    {
      "epoch": 1.217717114947143,
      "grad_norm": 0.5246235728263855,
      "learning_rate": 0.00015132878362103573,
      "loss": 0.3949,
      "step": 9100
    },
    {
      "epoch": 1.2244078683259736,
      "grad_norm": 0.7959131598472595,
      "learning_rate": 0.00015106115348588253,
      "loss": 0.3604,
      "step": 9150
    },
    {
      "epoch": 1.2310986217048039,
      "grad_norm": 0.2584095299243927,
      "learning_rate": 0.0001507935233507293,
      "loss": 0.3823,
      "step": 9200
    },
    {
      "epoch": 1.2377893750836344,
      "grad_norm": 0.512795627117157,
      "learning_rate": 0.0001505258932155761,
      "loss": 0.4012,
      "step": 9250
    },
    {
      "epoch": 1.244480128462465,
      "grad_norm": 0.46397605538368225,
      "learning_rate": 0.00015025826308042285,
      "loss": 0.3738,
      "step": 9300
    },
    {
      "epoch": 1.2511708818412952,
      "grad_norm": 0.5803693532943726,
      "learning_rate": 0.00014999063294526965,
      "loss": 0.4231,
      "step": 9350
    },
    {
      "epoch": 1.2578616352201257,
      "grad_norm": 0.8425002098083496,
      "learning_rate": 0.00014972300281011641,
      "loss": 0.3644,
      "step": 9400
    },
    {
      "epoch": 1.2645523885989562,
      "grad_norm": 1.4634531736373901,
      "learning_rate": 0.0001494553726749632,
      "loss": 0.3832,
      "step": 9450
    },
    {
      "epoch": 1.2712431419777868,
      "grad_norm": 0.369627445936203,
      "learning_rate": 0.00014918774253980997,
      "loss": 0.3972,
      "step": 9500
    },
    {
      "epoch": 1.2779338953566173,
      "grad_norm": 0.5950850248336792,
      "learning_rate": 0.00014892011240465677,
      "loss": 0.4024,
      "step": 9550
    },
    {
      "epoch": 1.2846246487354476,
      "grad_norm": 0.4019140601158142,
      "learning_rate": 0.00014865248226950353,
      "loss": 0.3607,
      "step": 9600
    },
    {
      "epoch": 1.291315402114278,
      "grad_norm": 2.5046777725219727,
      "learning_rate": 0.00014838485213435033,
      "loss": 0.3854,
      "step": 9650
    },
    {
      "epoch": 1.2980061554931086,
      "grad_norm": 0.885531485080719,
      "learning_rate": 0.00014811722199919712,
      "loss": 0.3891,
      "step": 9700
    },
    {
      "epoch": 1.304696908871939,
      "grad_norm": 0.4827861785888672,
      "learning_rate": 0.0001478495918640439,
      "loss": 0.3794,
      "step": 9750
    },
    {
      "epoch": 1.3113876622507694,
      "grad_norm": 0.7450051307678223,
      "learning_rate": 0.00014758196172889068,
      "loss": 0.3621,
      "step": 9800
    },
    {
      "epoch": 1.3180784156296,
      "grad_norm": 0.9007763266563416,
      "learning_rate": 0.00014731433159373747,
      "loss": 0.3613,
      "step": 9850
    },
    {
      "epoch": 1.3247691690084302,
      "grad_norm": 0.22630566358566284,
      "learning_rate": 0.00014704670145858424,
      "loss": 0.401,
      "step": 9900
    },
    {
      "epoch": 1.3314599223872607,
      "grad_norm": 0.5229451060295105,
      "learning_rate": 0.00014677907132343103,
      "loss": 0.3689,
      "step": 9950
    },
    {
      "epoch": 1.3381506757660913,
      "grad_norm": 0.8500617146492004,
      "learning_rate": 0.0001465114411882778,
      "loss": 0.4157,
      "step": 10000
    },
    {
      "epoch": 1.3448414291449218,
      "grad_norm": 0.25259721279144287,
      "learning_rate": 0.0001462438110531246,
      "loss": 0.3536,
      "step": 10050
    },
    {
      "epoch": 1.3515321825237523,
      "grad_norm": 0.3752908408641815,
      "learning_rate": 0.00014597618091797136,
      "loss": 0.3884,
      "step": 10100
    },
    {
      "epoch": 1.3582229359025826,
      "grad_norm": 0.8023069500923157,
      "learning_rate": 0.00014570855078281815,
      "loss": 0.3729,
      "step": 10150
    },
    {
      "epoch": 1.364913689281413,
      "grad_norm": 0.7075111269950867,
      "learning_rate": 0.00014544092064766492,
      "loss": 0.3844,
      "step": 10200
    },
    {
      "epoch": 1.3716044426602436,
      "grad_norm": 0.3746643364429474,
      "learning_rate": 0.0001451732905125117,
      "loss": 0.4316,
      "step": 10250
    },
    {
      "epoch": 1.378295196039074,
      "grad_norm": 0.8469864726066589,
      "learning_rate": 0.00014490566037735848,
      "loss": 0.3906,
      "step": 10300
    },
    {
      "epoch": 1.3849859494179044,
      "grad_norm": 0.44863101840019226,
      "learning_rate": 0.00014463803024220527,
      "loss": 0.4124,
      "step": 10350
    },
    {
      "epoch": 1.391676702796735,
      "grad_norm": 0.2043328732252121,
      "learning_rate": 0.00014437040010705204,
      "loss": 0.3989,
      "step": 10400
    },
    {
      "epoch": 1.3983674561755652,
      "grad_norm": 0.7363842129707336,
      "learning_rate": 0.00014410276997189883,
      "loss": 0.4025,
      "step": 10450
    },
    {
      "epoch": 1.4050582095543958,
      "grad_norm": 1.237909197807312,
      "learning_rate": 0.00014383513983674562,
      "loss": 0.398,
      "step": 10500
    },
    {
      "epoch": 1.4117489629332263,
      "grad_norm": 0.2752731442451477,
      "learning_rate": 0.00014356750970159242,
      "loss": 0.403,
      "step": 10550
    },
    {
      "epoch": 1.4184397163120568,
      "grad_norm": 0.6759665012359619,
      "learning_rate": 0.00014329987956643918,
      "loss": 0.4102,
      "step": 10600
    },
    {
      "epoch": 1.4251304696908873,
      "grad_norm": 0.18646712601184845,
      "learning_rate": 0.00014303224943128598,
      "loss": 0.3855,
      "step": 10650
    },
    {
      "epoch": 1.4318212230697176,
      "grad_norm": 0.7401400804519653,
      "learning_rate": 0.00014276461929613277,
      "loss": 0.3779,
      "step": 10700
    },
    {
      "epoch": 1.4385119764485481,
      "grad_norm": 0.28467991948127747,
      "learning_rate": 0.00014249698916097954,
      "loss": 0.3838,
      "step": 10750
    },
    {
      "epoch": 1.4452027298273786,
      "grad_norm": 0.5993130207061768,
      "learning_rate": 0.00014222935902582633,
      "loss": 0.3777,
      "step": 10800
    },
    {
      "epoch": 1.451893483206209,
      "grad_norm": 0.45999783277511597,
      "learning_rate": 0.0001419617288906731,
      "loss": 0.3719,
      "step": 10850
    },
    {
      "epoch": 1.4585842365850394,
      "grad_norm": 0.8294321894645691,
      "learning_rate": 0.0001416940987555199,
      "loss": 0.3812,
      "step": 10900
    },
    {
      "epoch": 1.46527498996387,
      "grad_norm": 0.7326551675796509,
      "learning_rate": 0.00014142646862036666,
      "loss": 0.3804,
      "step": 10950
    },
    {
      "epoch": 1.4719657433427003,
      "grad_norm": 0.16170567274093628,
      "learning_rate": 0.00014115883848521345,
      "loss": 0.3943,
      "step": 11000
    },
    {
      "epoch": 1.4786564967215308,
      "grad_norm": 0.40938231348991394,
      "learning_rate": 0.00014089120835006022,
      "loss": 0.4189,
      "step": 11050
    },
    {
      "epoch": 1.4853472501003613,
      "grad_norm": 0.49479159712791443,
      "learning_rate": 0.000140623578214907,
      "loss": 0.3728,
      "step": 11100
    },
    {
      "epoch": 1.4920380034791918,
      "grad_norm": 0.5468345880508423,
      "learning_rate": 0.00014035594807975378,
      "loss": 0.368,
      "step": 11150
    },
    {
      "epoch": 1.4987287568580223,
      "grad_norm": 0.2641042470932007,
      "learning_rate": 0.00014008831794460057,
      "loss": 0.4041,
      "step": 11200
    },
    {
      "epoch": 1.5054195102368526,
      "grad_norm": 0.9349272847175598,
      "learning_rate": 0.00013982068780944734,
      "loss": 0.3615,
      "step": 11250
    },
    {
      "epoch": 1.5121102636156831,
      "grad_norm": 0.4474796652793884,
      "learning_rate": 0.00013955305767429413,
      "loss": 0.3875,
      "step": 11300
    },
    {
      "epoch": 1.5188010169945136,
      "grad_norm": 0.5765525102615356,
      "learning_rate": 0.00013928542753914092,
      "loss": 0.3781,
      "step": 11350
    },
    {
      "epoch": 1.525491770373344,
      "grad_norm": 0.9323989748954773,
      "learning_rate": 0.00013901779740398772,
      "loss": 0.3727,
      "step": 11400
    },
    {
      "epoch": 1.5321825237521745,
      "grad_norm": 0.5866902470588684,
      "learning_rate": 0.00013875016726883448,
      "loss": 0.3837,
      "step": 11450
    },
    {
      "epoch": 1.538873277131005,
      "grad_norm": 0.23548507690429688,
      "learning_rate": 0.00013848253713368128,
      "loss": 0.3736,
      "step": 11500
    },
    {
      "epoch": 1.5455640305098353,
      "grad_norm": 0.6388257741928101,
      "learning_rate": 0.00013821490699852804,
      "loss": 0.3991,
      "step": 11550
    },
    {
      "epoch": 1.552254783888666,
      "grad_norm": 0.16709838807582855,
      "learning_rate": 0.00013794727686337484,
      "loss": 0.358,
      "step": 11600
    },
    {
      "epoch": 1.5589455372674963,
      "grad_norm": 0.49805784225463867,
      "learning_rate": 0.0001376796467282216,
      "loss": 0.3503,
      "step": 11650
    },
    {
      "epoch": 1.5656362906463268,
      "grad_norm": 0.1290799379348755,
      "learning_rate": 0.0001374120165930684,
      "loss": 0.3957,
      "step": 11700
    },
    {
      "epoch": 1.5723270440251573,
      "grad_norm": 0.34120726585388184,
      "learning_rate": 0.00013714438645791516,
      "loss": 0.375,
      "step": 11750
    },
    {
      "epoch": 1.5790177974039876,
      "grad_norm": 0.37449878454208374,
      "learning_rate": 0.00013687675632276196,
      "loss": 0.3994,
      "step": 11800
    },
    {
      "epoch": 1.5857085507828181,
      "grad_norm": 0.5091086030006409,
      "learning_rate": 0.00013660912618760872,
      "loss": 0.3595,
      "step": 11850
    },
    {
      "epoch": 1.5923993041616487,
      "grad_norm": 1.2273874282836914,
      "learning_rate": 0.00013634149605245552,
      "loss": 0.3796,
      "step": 11900
    },
    {
      "epoch": 1.599090057540479,
      "grad_norm": 0.2082648128271103,
      "learning_rate": 0.00013607386591730228,
      "loss": 0.414,
      "step": 11950
    },
    {
      "epoch": 1.6057808109193095,
      "grad_norm": 0.4675847887992859,
      "learning_rate": 0.00013580623578214907,
      "loss": 0.4069,
      "step": 12000
    },
    {
      "epoch": 1.61247156429814,
      "grad_norm": 0.3167395293712616,
      "learning_rate": 0.00013553860564699584,
      "loss": 0.3802,
      "step": 12050
    },
    {
      "epoch": 1.6191623176769703,
      "grad_norm": 0.9187132120132446,
      "learning_rate": 0.00013527097551184263,
      "loss": 0.4142,
      "step": 12100
    },
    {
      "epoch": 1.625853071055801,
      "grad_norm": 0.14601463079452515,
      "learning_rate": 0.00013500869797939248,
      "loss": 0.4229,
      "step": 12150
    },
    {
      "epoch": 1.6325438244346313,
      "grad_norm": 0.30309173464775085,
      "learning_rate": 0.00013474106784423928,
      "loss": 0.3602,
      "step": 12200
    },
    {
      "epoch": 1.6392345778134618,
      "grad_norm": 0.3843456208705902,
      "learning_rate": 0.00013447343770908604,
      "loss": 0.3686,
      "step": 12250
    },
    {
      "epoch": 1.6459253311922923,
      "grad_norm": 0.5596440434455872,
      "learning_rate": 0.00013420580757393284,
      "loss": 0.3533,
      "step": 12300
    },
    {
      "epoch": 1.6526160845711226,
      "grad_norm": 0.7922173142433167,
      "learning_rate": 0.0001339381774387796,
      "loss": 0.3379,
      "step": 12350
    },
    {
      "epoch": 1.6593068379499532,
      "grad_norm": 1.0290215015411377,
      "learning_rate": 0.0001336705473036264,
      "loss": 0.3677,
      "step": 12400
    },
    {
      "epoch": 1.6659975913287837,
      "grad_norm": 0.6741127371788025,
      "learning_rate": 0.00013340291716847316,
      "loss": 0.379,
      "step": 12450
    },
    {
      "epoch": 1.672688344707614,
      "grad_norm": 0.2614384889602661,
      "learning_rate": 0.00013313528703331996,
      "loss": 0.3998,
      "step": 12500
    },
    {
      "epoch": 1.6793790980864447,
      "grad_norm": 0.42598631978034973,
      "learning_rate": 0.00013286765689816675,
      "loss": 0.3638,
      "step": 12550
    },
    {
      "epoch": 1.686069851465275,
      "grad_norm": 0.30405953526496887,
      "learning_rate": 0.00013260002676301354,
      "loss": 0.3692,
      "step": 12600
    },
    {
      "epoch": 1.6927606048441053,
      "grad_norm": 1.2044662237167358,
      "learning_rate": 0.0001323323966278603,
      "loss": 0.3709,
      "step": 12650
    },
    {
      "epoch": 1.699451358222936,
      "grad_norm": 0.3721179664134979,
      "learning_rate": 0.0001320647664927071,
      "loss": 0.3871,
      "step": 12700
    },
    {
      "epoch": 1.7061421116017663,
      "grad_norm": 0.20860794186592102,
      "learning_rate": 0.00013179713635755387,
      "loss": 0.401,
      "step": 12750
    },
    {
      "epoch": 1.7128328649805968,
      "grad_norm": 0.664787232875824,
      "learning_rate": 0.00013152950622240066,
      "loss": 0.3715,
      "step": 12800
    },
    {
      "epoch": 1.7195236183594274,
      "grad_norm": 0.15741319954395294,
      "learning_rate": 0.00013126187608724743,
      "loss": 0.3759,
      "step": 12850
    },
    {
      "epoch": 1.7262143717382576,
      "grad_norm": 0.40116164088249207,
      "learning_rate": 0.00013099424595209422,
      "loss": 0.3761,
      "step": 12900
    },
    {
      "epoch": 1.7329051251170882,
      "grad_norm": 0.5465812087059021,
      "learning_rate": 0.000130726615816941,
      "loss": 0.3746,
      "step": 12950
    },
    {
      "epoch": 1.7395958784959187,
      "grad_norm": 0.5800393223762512,
      "learning_rate": 0.00013045898568178778,
      "loss": 0.3954,
      "step": 13000
    },
    {
      "epoch": 1.746286631874749,
      "grad_norm": 0.8798984289169312,
      "learning_rate": 0.00013019135554663455,
      "loss": 0.4039,
      "step": 13050
    },
    {
      "epoch": 1.7529773852535797,
      "grad_norm": 0.49841439723968506,
      "learning_rate": 0.00012992372541148134,
      "loss": 0.3802,
      "step": 13100
    },
    {
      "epoch": 1.75966813863241,
      "grad_norm": 0.8419637680053711,
      "learning_rate": 0.0001296560952763281,
      "loss": 0.4433,
      "step": 13150
    },
    {
      "epoch": 1.7663588920112403,
      "grad_norm": 0.42486879229545593,
      "learning_rate": 0.0001293884651411749,
      "loss": 0.438,
      "step": 13200
    },
    {
      "epoch": 1.773049645390071,
      "grad_norm": 0.6741183996200562,
      "learning_rate": 0.00012912083500602167,
      "loss": 0.3939,
      "step": 13250
    },
    {
      "epoch": 1.7797403987689013,
      "grad_norm": 0.8344675898551941,
      "learning_rate": 0.00012885320487086846,
      "loss": 0.3591,
      "step": 13300
    },
    {
      "epoch": 1.7864311521477318,
      "grad_norm": 0.2627742886543274,
      "learning_rate": 0.00012858557473571525,
      "loss": 0.3743,
      "step": 13350
    },
    {
      "epoch": 1.7931219055265624,
      "grad_norm": 0.5020785927772522,
      "learning_rate": 0.00012831794460056205,
      "loss": 0.3253,
      "step": 13400
    },
    {
      "epoch": 1.7998126589053927,
      "grad_norm": 0.4530200958251953,
      "learning_rate": 0.0001280503144654088,
      "loss": 0.3885,
      "step": 13450
    },
    {
      "epoch": 1.8065034122842232,
      "grad_norm": 0.3203600347042084,
      "learning_rate": 0.0001277826843302556,
      "loss": 0.3484,
      "step": 13500
    },
    {
      "epoch": 1.8131941656630537,
      "grad_norm": 0.4009936451911926,
      "learning_rate": 0.00012751505419510237,
      "loss": 0.3754,
      "step": 13550
    },
    {
      "epoch": 1.819884919041884,
      "grad_norm": 0.46801048517227173,
      "learning_rate": 0.00012724742405994917,
      "loss": 0.3943,
      "step": 13600
    },
    {
      "epoch": 1.8265756724207147,
      "grad_norm": 0.5235183835029602,
      "learning_rate": 0.00012697979392479593,
      "loss": 0.3833,
      "step": 13650
    },
    {
      "epoch": 1.833266425799545,
      "grad_norm": 0.3046988844871521,
      "learning_rate": 0.00012671216378964273,
      "loss": 0.3768,
      "step": 13700
    },
    {
      "epoch": 1.8399571791783755,
      "grad_norm": 1.0061575174331665,
      "learning_rate": 0.0001264445336544895,
      "loss": 0.3612,
      "step": 13750
    },
    {
      "epoch": 1.846647932557206,
      "grad_norm": 0.6865004897117615,
      "learning_rate": 0.00012617690351933629,
      "loss": 0.3882,
      "step": 13800
    },
    {
      "epoch": 1.8533386859360363,
      "grad_norm": 0.27292677760124207,
      "learning_rate": 0.00012590927338418305,
      "loss": 0.403,
      "step": 13850
    },
    {
      "epoch": 1.8600294393148669,
      "grad_norm": 1.1424332857131958,
      "learning_rate": 0.00012564164324902985,
      "loss": 0.436,
      "step": 13900
    },
    {
      "epoch": 1.8667201926936974,
      "grad_norm": 0.3957655429840088,
      "learning_rate": 0.0001253740131138766,
      "loss": 0.3746,
      "step": 13950
    },
    {
      "epoch": 1.8734109460725277,
      "grad_norm": 0.2877250909805298,
      "learning_rate": 0.0001251063829787234,
      "loss": 0.3611,
      "step": 14000
    },
    {
      "epoch": 1.8801016994513582,
      "grad_norm": 0.7024134397506714,
      "learning_rate": 0.00012483875284357017,
      "loss": 0.3813,
      "step": 14050
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.7420163750648499,
      "learning_rate": 0.00012457112270841697,
      "loss": 0.3532,
      "step": 14100
    },
    {
      "epoch": 1.893483206209019,
      "grad_norm": 0.5160520076751709,
      "learning_rate": 0.00012430349257326376,
      "loss": 0.4035,
      "step": 14150
    },
    {
      "epoch": 1.9001739595878497,
      "grad_norm": 0.4444162845611572,
      "learning_rate": 0.00012403586243811055,
      "loss": 0.3626,
      "step": 14200
    },
    {
      "epoch": 1.90686471296668,
      "grad_norm": 0.3605901598930359,
      "learning_rate": 0.00012376823230295732,
      "loss": 0.3614,
      "step": 14250
    },
    {
      "epoch": 1.9135554663455105,
      "grad_norm": 0.9058268666267395,
      "learning_rate": 0.0001235006021678041,
      "loss": 0.3874,
      "step": 14300
    },
    {
      "epoch": 1.920246219724341,
      "grad_norm": 0.4765203297138214,
      "learning_rate": 0.00012323832463535393,
      "loss": 0.3557,
      "step": 14350
    },
    {
      "epoch": 1.9269369731031714,
      "grad_norm": 0.6501011252403259,
      "learning_rate": 0.00012297069450020073,
      "loss": 0.373,
      "step": 14400
    },
    {
      "epoch": 1.9336277264820019,
      "grad_norm": 0.6897438168525696,
      "learning_rate": 0.0001227030643650475,
      "loss": 0.3535,
      "step": 14450
    },
    {
      "epoch": 1.9403184798608324,
      "grad_norm": 1.5989344120025635,
      "learning_rate": 0.00012243543422989429,
      "loss": 0.3711,
      "step": 14500
    },
    {
      "epoch": 1.9470092332396627,
      "grad_norm": 0.21199192106723785,
      "learning_rate": 0.00012216780409474108,
      "loss": 0.3705,
      "step": 14550
    },
    {
      "epoch": 1.9536999866184932,
      "grad_norm": 0.3149133622646332,
      "learning_rate": 0.00012190017395958786,
      "loss": 0.381,
      "step": 14600
    },
    {
      "epoch": 1.9603907399973237,
      "grad_norm": 0.292575865983963,
      "learning_rate": 0.00012163254382443463,
      "loss": 0.4122,
      "step": 14650
    },
    {
      "epoch": 1.967081493376154,
      "grad_norm": 0.2877853810787201,
      "learning_rate": 0.00012136491368928142,
      "loss": 0.4069,
      "step": 14700
    },
    {
      "epoch": 1.9737722467549847,
      "grad_norm": 0.7131567597389221,
      "learning_rate": 0.0001210972835541282,
      "loss": 0.3811,
      "step": 14750
    },
    {
      "epoch": 1.980463000133815,
      "grad_norm": 0.5183832049369812,
      "learning_rate": 0.00012082965341897499,
      "loss": 0.3715,
      "step": 14800
    },
    {
      "epoch": 1.9871537535126456,
      "grad_norm": 0.21618179976940155,
      "learning_rate": 0.00012056202328382176,
      "loss": 0.4114,
      "step": 14850
    },
    {
      "epoch": 1.993844506891476,
      "grad_norm": 1.0447479486465454,
      "learning_rate": 0.00012029439314866855,
      "loss": 0.4258,
      "step": 14900
    },
    {
      "epoch": 2.0005352602703064,
      "grad_norm": 0.4689196050167084,
      "learning_rate": 0.00012002676301351532,
      "loss": 0.4021,
      "step": 14950
    },
    {
      "epoch": 2.007226013649137,
      "grad_norm": 0.5421102046966553,
      "learning_rate": 0.00011975913287836211,
      "loss": 0.3535,
      "step": 15000
    },
    {
      "epoch": 2.0139167670279674,
      "grad_norm": 0.22121213376522064,
      "learning_rate": 0.00011949150274320888,
      "loss": 0.3582,
      "step": 15050
    },
    {
      "epoch": 2.0206075204067977,
      "grad_norm": 0.37987565994262695,
      "learning_rate": 0.00011922387260805567,
      "loss": 0.3991,
      "step": 15100
    },
    {
      "epoch": 2.0272982737856284,
      "grad_norm": 0.396880179643631,
      "learning_rate": 0.00011895624247290245,
      "loss": 0.3416,
      "step": 15150
    },
    {
      "epoch": 2.0339890271644587,
      "grad_norm": 0.3051856458187103,
      "learning_rate": 0.00011868861233774924,
      "loss": 0.3577,
      "step": 15200
    },
    {
      "epoch": 2.040679780543289,
      "grad_norm": 1.8450953960418701,
      "learning_rate": 0.00011842098220259601,
      "loss": 0.3525,
      "step": 15250
    },
    {
      "epoch": 2.0473705339221198,
      "grad_norm": 0.31630465388298035,
      "learning_rate": 0.0001181533520674428,
      "loss": 0.4072,
      "step": 15300
    },
    {
      "epoch": 2.05406128730095,
      "grad_norm": 1.3400176763534546,
      "learning_rate": 0.00011788572193228957,
      "loss": 0.3624,
      "step": 15350
    },
    {
      "epoch": 2.0607520406797804,
      "grad_norm": 0.8910712599754333,
      "learning_rate": 0.00011761809179713636,
      "loss": 0.3774,
      "step": 15400
    },
    {
      "epoch": 2.067442794058611,
      "grad_norm": 0.5161178708076477,
      "learning_rate": 0.00011735046166198313,
      "loss": 0.4268,
      "step": 15450
    },
    {
      "epoch": 2.0741335474374414,
      "grad_norm": 0.40613117814064026,
      "learning_rate": 0.00011708283152682992,
      "loss": 0.3599,
      "step": 15500
    },
    {
      "epoch": 2.080824300816272,
      "grad_norm": 0.9049540758132935,
      "learning_rate": 0.0001168152013916767,
      "loss": 0.3873,
      "step": 15550
    },
    {
      "epoch": 2.0875150541951024,
      "grad_norm": 0.2763298749923706,
      "learning_rate": 0.0001165475712565235,
      "loss": 0.3727,
      "step": 15600
    },
    {
      "epoch": 2.0942058075739327,
      "grad_norm": 1.114091157913208,
      "learning_rate": 0.00011627994112137026,
      "loss": 0.3758,
      "step": 15650
    },
    {
      "epoch": 2.1008965609527634,
      "grad_norm": 0.20970086753368378,
      "learning_rate": 0.00011601231098621706,
      "loss": 0.3667,
      "step": 15700
    },
    {
      "epoch": 2.1075873143315937,
      "grad_norm": 0.48983532190322876,
      "learning_rate": 0.00011574468085106382,
      "loss": 0.3645,
      "step": 15750
    },
    {
      "epoch": 2.114278067710424,
      "grad_norm": 0.22365806996822357,
      "learning_rate": 0.00011547705071591062,
      "loss": 0.3811,
      "step": 15800
    },
    {
      "epoch": 2.1209688210892548,
      "grad_norm": 0.305634468793869,
      "learning_rate": 0.00011520942058075738,
      "loss": 0.3673,
      "step": 15850
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 0.1949058175086975,
      "learning_rate": 0.00011494179044560418,
      "loss": 0.3459,
      "step": 15900
    },
    {
      "epoch": 2.1343503278469154,
      "grad_norm": 1.6863826513290405,
      "learning_rate": 0.00011467416031045097,
      "loss": 0.3987,
      "step": 15950
    },
    {
      "epoch": 2.141041081225746,
      "grad_norm": 0.39809972047805786,
      "learning_rate": 0.00011440653017529775,
      "loss": 0.361,
      "step": 16000
    },
    {
      "epoch": 2.1477318346045764,
      "grad_norm": 1.12253737449646,
      "learning_rate": 0.00011413890004014454,
      "loss": 0.3688,
      "step": 16050
    },
    {
      "epoch": 2.154422587983407,
      "grad_norm": 0.6563467979431152,
      "learning_rate": 0.00011387126990499131,
      "loss": 0.3902,
      "step": 16100
    },
    {
      "epoch": 2.1611133413622374,
      "grad_norm": 0.352318674325943,
      "learning_rate": 0.0001136036397698381,
      "loss": 0.3713,
      "step": 16150
    },
    {
      "epoch": 2.1678040947410677,
      "grad_norm": 0.8300108313560486,
      "learning_rate": 0.00011333600963468487,
      "loss": 0.3985,
      "step": 16200
    },
    {
      "epoch": 2.1744948481198985,
      "grad_norm": 0.6930580735206604,
      "learning_rate": 0.00011306837949953166,
      "loss": 0.3388,
      "step": 16250
    },
    {
      "epoch": 2.1811856014987288,
      "grad_norm": 0.4945830702781677,
      "learning_rate": 0.00011280074936437843,
      "loss": 0.3827,
      "step": 16300
    },
    {
      "epoch": 2.187876354877559,
      "grad_norm": 0.92209792137146,
      "learning_rate": 0.00011253311922922522,
      "loss": 0.3462,
      "step": 16350
    },
    {
      "epoch": 2.19456710825639,
      "grad_norm": 0.5691097974777222,
      "learning_rate": 0.000112265489094072,
      "loss": 0.3738,
      "step": 16400
    },
    {
      "epoch": 2.20125786163522,
      "grad_norm": 0.24852952361106873,
      "learning_rate": 0.0001119978589589188,
      "loss": 0.3571,
      "step": 16450
    },
    {
      "epoch": 2.2079486150140504,
      "grad_norm": 0.5234774947166443,
      "learning_rate": 0.00011173022882376556,
      "loss": 0.3771,
      "step": 16500
    },
    {
      "epoch": 2.214639368392881,
      "grad_norm": 0.592340886592865,
      "learning_rate": 0.00011146259868861236,
      "loss": 0.3468,
      "step": 16550
    },
    {
      "epoch": 2.2213301217717114,
      "grad_norm": 0.211746484041214,
      "learning_rate": 0.00011119496855345912,
      "loss": 0.3517,
      "step": 16600
    },
    {
      "epoch": 2.228020875150542,
      "grad_norm": 0.4191420078277588,
      "learning_rate": 0.00011092733841830591,
      "loss": 0.3802,
      "step": 16650
    },
    {
      "epoch": 2.2347116285293724,
      "grad_norm": 0.6590503454208374,
      "learning_rate": 0.00011065970828315268,
      "loss": 0.3728,
      "step": 16700
    },
    {
      "epoch": 2.2414023819082027,
      "grad_norm": 0.1558094024658203,
      "learning_rate": 0.00011039207814799947,
      "loss": 0.3502,
      "step": 16750
    },
    {
      "epoch": 2.2480931352870335,
      "grad_norm": 0.6953702569007874,
      "learning_rate": 0.00011012444801284625,
      "loss": 0.3618,
      "step": 16800
    },
    {
      "epoch": 2.2547838886658638,
      "grad_norm": 0.8811017274856567,
      "learning_rate": 0.00010986217048039609,
      "loss": 0.3379,
      "step": 16850
    },
    {
      "epoch": 2.261474642044694,
      "grad_norm": 0.6629860401153564,
      "learning_rate": 0.00010959454034524288,
      "loss": 0.3576,
      "step": 16900
    },
    {
      "epoch": 2.268165395423525,
      "grad_norm": 0.3507874310016632,
      "learning_rate": 0.00010932691021008965,
      "loss": 0.4008,
      "step": 16950
    },
    {
      "epoch": 2.274856148802355,
      "grad_norm": 0.16495244204998016,
      "learning_rate": 0.00010905928007493644,
      "loss": 0.3642,
      "step": 17000
    },
    {
      "epoch": 2.2815469021811854,
      "grad_norm": 0.7053512930870056,
      "learning_rate": 0.00010879164993978324,
      "loss": 0.3677,
      "step": 17050
    },
    {
      "epoch": 2.288237655560016,
      "grad_norm": 0.6226108074188232,
      "learning_rate": 0.00010852401980463,
      "loss": 0.3783,
      "step": 17100
    },
    {
      "epoch": 2.2949284089388464,
      "grad_norm": 0.6966596245765686,
      "learning_rate": 0.0001082563896694768,
      "loss": 0.3618,
      "step": 17150
    },
    {
      "epoch": 2.301619162317677,
      "grad_norm": 0.6026417016983032,
      "learning_rate": 0.00010798875953432358,
      "loss": 0.359,
      "step": 17200
    },
    {
      "epoch": 2.3083099156965075,
      "grad_norm": 0.3976234793663025,
      "learning_rate": 0.00010772112939917036,
      "loss": 0.3522,
      "step": 17250
    },
    {
      "epoch": 2.3150006690753377,
      "grad_norm": 0.6865359544754028,
      "learning_rate": 0.00010745349926401713,
      "loss": 0.3665,
      "step": 17300
    },
    {
      "epoch": 2.3216914224541685,
      "grad_norm": 0.19888201355934143,
      "learning_rate": 0.00010718586912886393,
      "loss": 0.3959,
      "step": 17350
    },
    {
      "epoch": 2.328382175832999,
      "grad_norm": 0.40732085704803467,
      "learning_rate": 0.0001069182389937107,
      "loss": 0.3766,
      "step": 17400
    },
    {
      "epoch": 2.335072929211829,
      "grad_norm": 0.5637026429176331,
      "learning_rate": 0.00010665060885855749,
      "loss": 0.3792,
      "step": 17450
    },
    {
      "epoch": 2.34176368259066,
      "grad_norm": 0.39482682943344116,
      "learning_rate": 0.00010638297872340425,
      "loss": 0.3633,
      "step": 17500
    },
    {
      "epoch": 2.34845443596949,
      "grad_norm": 0.5431216359138489,
      "learning_rate": 0.00010611534858825105,
      "loss": 0.3562,
      "step": 17550
    },
    {
      "epoch": 2.3551451893483204,
      "grad_norm": 0.7218997478485107,
      "learning_rate": 0.00010584771845309783,
      "loss": 0.3423,
      "step": 17600
    },
    {
      "epoch": 2.361835942727151,
      "grad_norm": 0.4792058765888214,
      "learning_rate": 0.00010558008831794462,
      "loss": 0.3598,
      "step": 17650
    },
    {
      "epoch": 2.3685266961059814,
      "grad_norm": 0.5000917911529541,
      "learning_rate": 0.00010531245818279139,
      "loss": 0.3796,
      "step": 17700
    },
    {
      "epoch": 2.375217449484812,
      "grad_norm": 0.4030153751373291,
      "learning_rate": 0.00010504482804763818,
      "loss": 0.3879,
      "step": 17750
    },
    {
      "epoch": 2.3819082028636425,
      "grad_norm": 0.2075815051794052,
      "learning_rate": 0.00010477719791248495,
      "loss": 0.383,
      "step": 17800
    },
    {
      "epoch": 2.3885989562424728,
      "grad_norm": 0.5363799333572388,
      "learning_rate": 0.00010450956777733174,
      "loss": 0.3479,
      "step": 17850
    },
    {
      "epoch": 2.3952897096213035,
      "grad_norm": 0.6737052798271179,
      "learning_rate": 0.00010424193764217851,
      "loss": 0.359,
      "step": 17900
    },
    {
      "epoch": 2.401980463000134,
      "grad_norm": 0.4461873471736908,
      "learning_rate": 0.0001039743075070253,
      "loss": 0.3788,
      "step": 17950
    },
    {
      "epoch": 2.408671216378964,
      "grad_norm": 0.3517526090145111,
      "learning_rate": 0.00010370667737187208,
      "loss": 0.3836,
      "step": 18000
    },
    {
      "epoch": 2.415361969757795,
      "grad_norm": 0.37667033076286316,
      "learning_rate": 0.00010343904723671887,
      "loss": 0.3778,
      "step": 18050
    },
    {
      "epoch": 2.422052723136625,
      "grad_norm": 0.6058921217918396,
      "learning_rate": 0.00010317141710156564,
      "loss": 0.3956,
      "step": 18100
    },
    {
      "epoch": 2.4287434765154554,
      "grad_norm": 0.2507612407207489,
      "learning_rate": 0.00010290378696641243,
      "loss": 0.3666,
      "step": 18150
    },
    {
      "epoch": 2.435434229894286,
      "grad_norm": 0.83463454246521,
      "learning_rate": 0.0001026361568312592,
      "loss": 0.3466,
      "step": 18200
    },
    {
      "epoch": 2.4421249832731164,
      "grad_norm": 0.7671091556549072,
      "learning_rate": 0.00010236852669610599,
      "loss": 0.3668,
      "step": 18250
    },
    {
      "epoch": 2.448815736651947,
      "grad_norm": 1.1214767694473267,
      "learning_rate": 0.00010210089656095276,
      "loss": 0.3716,
      "step": 18300
    },
    {
      "epoch": 2.4555064900307775,
      "grad_norm": 0.4941485524177551,
      "learning_rate": 0.00010183326642579955,
      "loss": 0.3864,
      "step": 18350
    },
    {
      "epoch": 2.4621972434096078,
      "grad_norm": 0.16478529572486877,
      "learning_rate": 0.00010156563629064633,
      "loss": 0.3771,
      "step": 18400
    },
    {
      "epoch": 2.4688879967884385,
      "grad_norm": 0.31831037998199463,
      "learning_rate": 0.00010129800615549313,
      "loss": 0.3597,
      "step": 18450
    },
    {
      "epoch": 2.475578750167269,
      "grad_norm": 0.6194308400154114,
      "learning_rate": 0.00010103037602033989,
      "loss": 0.3706,
      "step": 18500
    },
    {
      "epoch": 2.482269503546099,
      "grad_norm": 0.2916397154331207,
      "learning_rate": 0.00010076274588518669,
      "loss": 0.4122,
      "step": 18550
    },
    {
      "epoch": 2.48896025692493,
      "grad_norm": 0.6374987959861755,
      "learning_rate": 0.00010049511575003345,
      "loss": 0.3547,
      "step": 18600
    },
    {
      "epoch": 2.49565101030376,
      "grad_norm": 0.3186698853969574,
      "learning_rate": 0.00010022748561488025,
      "loss": 0.3323,
      "step": 18650
    },
    {
      "epoch": 2.5023417636825904,
      "grad_norm": 0.43695852160453796,
      "learning_rate": 9.995985547972703e-05,
      "loss": 0.3627,
      "step": 18700
    },
    {
      "epoch": 2.509032517061421,
      "grad_norm": 0.7127928137779236,
      "learning_rate": 9.96922253445738e-05,
      "loss": 0.3475,
      "step": 18750
    },
    {
      "epoch": 2.5157232704402515,
      "grad_norm": 0.3883754312992096,
      "learning_rate": 9.942459520942058e-05,
      "loss": 0.3569,
      "step": 18800
    },
    {
      "epoch": 2.522414023819082,
      "grad_norm": 1.0758856534957886,
      "learning_rate": 9.915696507426738e-05,
      "loss": 0.3334,
      "step": 18850
    },
    {
      "epoch": 2.5291047771979125,
      "grad_norm": 0.28019794821739197,
      "learning_rate": 9.888933493911416e-05,
      "loss": 0.3737,
      "step": 18900
    },
    {
      "epoch": 2.535795530576743,
      "grad_norm": 0.5006274580955505,
      "learning_rate": 9.862170480396094e-05,
      "loss": 0.3675,
      "step": 18950
    },
    {
      "epoch": 2.5424862839555735,
      "grad_norm": 0.4710283875465393,
      "learning_rate": 9.835407466880772e-05,
      "loss": 0.3364,
      "step": 19000
    },
    {
      "epoch": 2.549177037334404,
      "grad_norm": 0.3176027238368988,
      "learning_rate": 9.80864445336545e-05,
      "loss": 0.3781,
      "step": 19050
    },
    {
      "epoch": 2.5558677907132346,
      "grad_norm": 0.22631238400936127,
      "learning_rate": 9.781881439850128e-05,
      "loss": 0.3589,
      "step": 19100
    },
    {
      "epoch": 2.562558544092065,
      "grad_norm": 0.4166819155216217,
      "learning_rate": 9.755118426334806e-05,
      "loss": 0.3447,
      "step": 19150
    },
    {
      "epoch": 2.569249297470895,
      "grad_norm": 0.9090126752853394,
      "learning_rate": 9.728355412819484e-05,
      "loss": 0.405,
      "step": 19200
    },
    {
      "epoch": 2.5759400508497254,
      "grad_norm": 0.2107497751712799,
      "learning_rate": 9.701592399304163e-05,
      "loss": 0.3586,
      "step": 19250
    },
    {
      "epoch": 2.582630804228556,
      "grad_norm": 0.2312631458044052,
      "learning_rate": 9.674829385788841e-05,
      "loss": 0.3745,
      "step": 19300
    },
    {
      "epoch": 2.5893215576073865,
      "grad_norm": 1.4408315420150757,
      "learning_rate": 9.648066372273519e-05,
      "loss": 0.353,
      "step": 19350
    },
    {
      "epoch": 2.596012310986217,
      "grad_norm": 0.28962549567222595,
      "learning_rate": 9.621303358758197e-05,
      "loss": 0.38,
      "step": 19400
    },
    {
      "epoch": 2.6027030643650475,
      "grad_norm": 0.34764039516448975,
      "learning_rate": 9.59507560551318e-05,
      "loss": 0.375,
      "step": 19450
    },
    {
      "epoch": 2.609393817743878,
      "grad_norm": 0.3141617476940155,
      "learning_rate": 9.568312591997858e-05,
      "loss": 0.3325,
      "step": 19500
    },
    {
      "epoch": 2.6160845711227085,
      "grad_norm": 0.307822585105896,
      "learning_rate": 9.541549578482536e-05,
      "loss": 0.3465,
      "step": 19550
    },
    {
      "epoch": 2.622775324501539,
      "grad_norm": 0.46695834398269653,
      "learning_rate": 9.514786564967216e-05,
      "loss": 0.3372,
      "step": 19600
    },
    {
      "epoch": 2.6294660778803696,
      "grad_norm": 0.3919815123081207,
      "learning_rate": 9.488023551451894e-05,
      "loss": 0.3293,
      "step": 19650
    },
    {
      "epoch": 2.6361568312592,
      "grad_norm": 0.6823663711547852,
      "learning_rate": 9.461260537936573e-05,
      "loss": 0.4303,
      "step": 19700
    },
    {
      "epoch": 2.64284758463803,
      "grad_norm": 0.6681721210479736,
      "learning_rate": 9.434497524421251e-05,
      "loss": 0.3776,
      "step": 19750
    },
    {
      "epoch": 2.6495383380168605,
      "grad_norm": 0.8174289464950562,
      "learning_rate": 9.407734510905929e-05,
      "loss": 0.3723,
      "step": 19800
    },
    {
      "epoch": 2.656229091395691,
      "grad_norm": 0.6442592144012451,
      "learning_rate": 9.380971497390607e-05,
      "loss": 0.3626,
      "step": 19850
    },
    {
      "epoch": 2.6629198447745215,
      "grad_norm": 0.4354235529899597,
      "learning_rate": 9.354208483875285e-05,
      "loss": 0.3685,
      "step": 19900
    },
    {
      "epoch": 2.669610598153352,
      "grad_norm": 0.2793715000152588,
      "learning_rate": 9.327445470359963e-05,
      "loss": 0.3347,
      "step": 19950
    },
    {
      "epoch": 2.6763013515321825,
      "grad_norm": 0.46320897340774536,
      "learning_rate": 9.300682456844641e-05,
      "loss": 0.3571,
      "step": 20000
    },
    {
      "epoch": 2.682992104911013,
      "grad_norm": 1.9111179113388062,
      "learning_rate": 9.27391944332932e-05,
      "loss": 0.3732,
      "step": 20050
    },
    {
      "epoch": 2.6896828582898435,
      "grad_norm": 0.43122464418411255,
      "learning_rate": 9.247156429813998e-05,
      "loss": 0.3321,
      "step": 20100
    },
    {
      "epoch": 2.696373611668674,
      "grad_norm": 0.2496163249015808,
      "learning_rate": 9.220393416298676e-05,
      "loss": 0.358,
      "step": 20150
    },
    {
      "epoch": 2.7030643650475046,
      "grad_norm": 0.3517436683177948,
      "learning_rate": 9.193630402783354e-05,
      "loss": 0.367,
      "step": 20200
    },
    {
      "epoch": 2.709755118426335,
      "grad_norm": 1.1649861335754395,
      "learning_rate": 9.166867389268032e-05,
      "loss": 0.3464,
      "step": 20250
    },
    {
      "epoch": 2.716445871805165,
      "grad_norm": 0.6548661589622498,
      "learning_rate": 9.14010437575271e-05,
      "loss": 0.3472,
      "step": 20300
    },
    {
      "epoch": 2.7231366251839955,
      "grad_norm": 0.22872941195964813,
      "learning_rate": 9.113341362237388e-05,
      "loss": 0.3577,
      "step": 20350
    },
    {
      "epoch": 2.729827378562826,
      "grad_norm": 0.6476384401321411,
      "learning_rate": 9.086578348722066e-05,
      "loss": 0.3932,
      "step": 20400
    },
    {
      "epoch": 2.7365181319416565,
      "grad_norm": 0.3706994354724884,
      "learning_rate": 9.059815335206746e-05,
      "loss": 0.3772,
      "step": 20450
    },
    {
      "epoch": 2.7432088853204872,
      "grad_norm": 0.3707790672779083,
      "learning_rate": 9.033052321691424e-05,
      "loss": 0.3518,
      "step": 20500
    },
    {
      "epoch": 2.7498996386993175,
      "grad_norm": 0.19738784432411194,
      "learning_rate": 9.006289308176102e-05,
      "loss": 0.3751,
      "step": 20550
    },
    {
      "epoch": 2.756590392078148,
      "grad_norm": 0.195155531167984,
      "learning_rate": 8.97952629466078e-05,
      "loss": 0.3238,
      "step": 20600
    },
    {
      "epoch": 2.7632811454569786,
      "grad_norm": 0.3838144838809967,
      "learning_rate": 8.952763281145458e-05,
      "loss": 0.3524,
      "step": 20650
    },
    {
      "epoch": 2.769971898835809,
      "grad_norm": 0.3640313744544983,
      "learning_rate": 8.926000267630136e-05,
      "loss": 0.3529,
      "step": 20700
    },
    {
      "epoch": 2.7766626522146396,
      "grad_norm": 0.3057290017604828,
      "learning_rate": 8.899237254114814e-05,
      "loss": 0.3662,
      "step": 20750
    },
    {
      "epoch": 2.78335340559347,
      "grad_norm": 0.8710340261459351,
      "learning_rate": 8.872474240599492e-05,
      "loss": 0.3622,
      "step": 20800
    },
    {
      "epoch": 2.7900441589723,
      "grad_norm": 0.23047395050525665,
      "learning_rate": 8.845711227084171e-05,
      "loss": 0.408,
      "step": 20850
    },
    {
      "epoch": 2.7967349123511305,
      "grad_norm": 1.0726213455200195,
      "learning_rate": 8.818948213568849e-05,
      "loss": 0.3582,
      "step": 20900
    },
    {
      "epoch": 2.803425665729961,
      "grad_norm": 0.23616532981395721,
      "learning_rate": 8.792185200053527e-05,
      "loss": 0.371,
      "step": 20950
    },
    {
      "epoch": 2.8101164191087915,
      "grad_norm": 0.3996395766735077,
      "learning_rate": 8.765422186538205e-05,
      "loss": 0.3823,
      "step": 21000
    },
    {
      "epoch": 2.8168071724876222,
      "grad_norm": 0.3436138927936554,
      "learning_rate": 8.738659173022883e-05,
      "loss": 0.3922,
      "step": 21050
    },
    {
      "epoch": 2.8234979258664525,
      "grad_norm": 1.0888837575912476,
      "learning_rate": 8.711896159507561e-05,
      "loss": 0.4023,
      "step": 21100
    },
    {
      "epoch": 2.830188679245283,
      "grad_norm": 0.4303966760635376,
      "learning_rate": 8.685133145992239e-05,
      "loss": 0.3622,
      "step": 21150
    },
    {
      "epoch": 2.8368794326241136,
      "grad_norm": 0.8068354725837708,
      "learning_rate": 8.658370132476917e-05,
      "loss": 0.3763,
      "step": 21200
    },
    {
      "epoch": 2.843570186002944,
      "grad_norm": 0.23964738845825195,
      "learning_rate": 8.631607118961596e-05,
      "loss": 0.3699,
      "step": 21250
    },
    {
      "epoch": 2.8502609393817746,
      "grad_norm": 0.4074212312698364,
      "learning_rate": 8.604844105446274e-05,
      "loss": 0.3624,
      "step": 21300
    },
    {
      "epoch": 2.856951692760605,
      "grad_norm": 0.9525429606437683,
      "learning_rate": 8.578081091930952e-05,
      "loss": 0.3589,
      "step": 21350
    },
    {
      "epoch": 2.863642446139435,
      "grad_norm": 0.5361550450325012,
      "learning_rate": 8.55131807841563e-05,
      "loss": 0.3735,
      "step": 21400
    },
    {
      "epoch": 2.8703331995182655,
      "grad_norm": 0.6495856046676636,
      "learning_rate": 8.524555064900308e-05,
      "loss": 0.3669,
      "step": 21450
    },
    {
      "epoch": 2.8770239528970962,
      "grad_norm": 0.49792200326919556,
      "learning_rate": 8.497792051384986e-05,
      "loss": 0.3576,
      "step": 21500
    },
    {
      "epoch": 2.8837147062759265,
      "grad_norm": 0.8315381407737732,
      "learning_rate": 8.471029037869664e-05,
      "loss": 0.3429,
      "step": 21550
    },
    {
      "epoch": 2.8904054596547573,
      "grad_norm": 0.7096693515777588,
      "learning_rate": 8.444266024354342e-05,
      "loss": 0.371,
      "step": 21600
    },
    {
      "epoch": 2.8970962130335876,
      "grad_norm": 1.0328216552734375,
      "learning_rate": 8.417503010839021e-05,
      "loss": 0.3594,
      "step": 21650
    },
    {
      "epoch": 2.903786966412418,
      "grad_norm": 0.5857737064361572,
      "learning_rate": 8.391275257594006e-05,
      "loss": 0.3473,
      "step": 21700
    },
    {
      "epoch": 2.9104777197912486,
      "grad_norm": 0.16210222244262695,
      "learning_rate": 8.364512244078684e-05,
      "loss": 0.3616,
      "step": 21750
    },
    {
      "epoch": 2.917168473170079,
      "grad_norm": 0.5218638181686401,
      "learning_rate": 8.337749230563362e-05,
      "loss": 0.371,
      "step": 21800
    },
    {
      "epoch": 2.9238592265489096,
      "grad_norm": 0.773952841758728,
      "learning_rate": 8.31098621704804e-05,
      "loss": 0.3549,
      "step": 21850
    },
    {
      "epoch": 2.93054997992774,
      "grad_norm": 0.2386569231748581,
      "learning_rate": 8.284223203532718e-05,
      "loss": 0.3707,
      "step": 21900
    },
    {
      "epoch": 2.93724073330657,
      "grad_norm": 0.259430855512619,
      "learning_rate": 8.257460190017396e-05,
      "loss": 0.3625,
      "step": 21950
    },
    {
      "epoch": 2.9439314866854005,
      "grad_norm": 0.3941461145877838,
      "learning_rate": 8.230697176502074e-05,
      "loss": 0.3516,
      "step": 22000
    },
    {
      "epoch": 2.9506222400642312,
      "grad_norm": 0.3092714548110962,
      "learning_rate": 8.203934162986752e-05,
      "loss": 0.3773,
      "step": 22050
    },
    {
      "epoch": 2.9573129934430615,
      "grad_norm": 0.397014856338501,
      "learning_rate": 8.177171149471431e-05,
      "loss": 0.3428,
      "step": 22100
    },
    {
      "epoch": 2.9640037468218923,
      "grad_norm": 0.21178485453128815,
      "learning_rate": 8.15040813595611e-05,
      "loss": 0.3407,
      "step": 22150
    },
    {
      "epoch": 2.9706945002007226,
      "grad_norm": 0.40657421946525574,
      "learning_rate": 8.123645122440787e-05,
      "loss": 0.3643,
      "step": 22200
    },
    {
      "epoch": 2.977385253579553,
      "grad_norm": 0.6081882119178772,
      "learning_rate": 8.096882108925465e-05,
      "loss": 0.3722,
      "step": 22250
    },
    {
      "epoch": 2.9840760069583836,
      "grad_norm": 0.8416446447372437,
      "learning_rate": 8.070119095410143e-05,
      "loss": 0.3593,
      "step": 22300
    },
    {
      "epoch": 2.990766760337214,
      "grad_norm": 0.46739161014556885,
      "learning_rate": 8.043356081894821e-05,
      "loss": 0.3664,
      "step": 22350
    },
    {
      "epoch": 2.9974575137160446,
      "grad_norm": 0.4644850194454193,
      "learning_rate": 8.0165930683795e-05,
      "loss": 0.3604,
      "step": 22400
    },
    {
      "epoch": 3.004148267094875,
      "grad_norm": 1.2540395259857178,
      "learning_rate": 7.989830054864177e-05,
      "loss": 0.3526,
      "step": 22450
    },
    {
      "epoch": 3.010839020473705,
      "grad_norm": 0.29698461294174194,
      "learning_rate": 7.963067041348857e-05,
      "loss": 0.3462,
      "step": 22500
    },
    {
      "epoch": 3.017529773852536,
      "grad_norm": 0.33558788895606995,
      "learning_rate": 7.936304027833535e-05,
      "loss": 0.3461,
      "step": 22550
    },
    {
      "epoch": 3.0242205272313663,
      "grad_norm": 0.35622140765190125,
      "learning_rate": 7.909541014318213e-05,
      "loss": 0.3265,
      "step": 22600
    },
    {
      "epoch": 3.0309112806101965,
      "grad_norm": 0.5862126350402832,
      "learning_rate": 7.88277800080289e-05,
      "loss": 0.3705,
      "step": 22650
    },
    {
      "epoch": 3.0376020339890273,
      "grad_norm": 0.2739565670490265,
      "learning_rate": 7.856014987287569e-05,
      "loss": 0.3337,
      "step": 22700
    },
    {
      "epoch": 3.0442927873678576,
      "grad_norm": 0.3305657207965851,
      "learning_rate": 7.829251973772247e-05,
      "loss": 0.3247,
      "step": 22750
    },
    {
      "epoch": 3.050983540746688,
      "grad_norm": 0.3107627034187317,
      "learning_rate": 7.802488960256925e-05,
      "loss": 0.3699,
      "step": 22800
    },
    {
      "epoch": 3.0576742941255186,
      "grad_norm": 0.679939866065979,
      "learning_rate": 7.775725946741604e-05,
      "loss": 0.3693,
      "step": 22850
    },
    {
      "epoch": 3.064365047504349,
      "grad_norm": 0.3857807219028473,
      "learning_rate": 7.748962933226282e-05,
      "loss": 0.3466,
      "step": 22900
    },
    {
      "epoch": 3.0710558008831796,
      "grad_norm": 1.193116307258606,
      "learning_rate": 7.72219991971096e-05,
      "loss": 0.3577,
      "step": 22950
    },
    {
      "epoch": 3.07774655426201,
      "grad_norm": 0.7366277575492859,
      "learning_rate": 7.695436906195638e-05,
      "loss": 0.3658,
      "step": 23000
    },
    {
      "epoch": 3.0844373076408402,
      "grad_norm": 0.2952132523059845,
      "learning_rate": 7.668673892680316e-05,
      "loss": 0.3532,
      "step": 23050
    },
    {
      "epoch": 3.091128061019671,
      "grad_norm": 0.3019171357154846,
      "learning_rate": 7.641910879164994e-05,
      "loss": 0.3593,
      "step": 23100
    },
    {
      "epoch": 3.0978188143985013,
      "grad_norm": 0.40697696805000305,
      "learning_rate": 7.615147865649672e-05,
      "loss": 0.3607,
      "step": 23150
    },
    {
      "epoch": 3.1045095677773316,
      "grad_norm": 0.8781392574310303,
      "learning_rate": 7.58838485213435e-05,
      "loss": 0.3397,
      "step": 23200
    },
    {
      "epoch": 3.1112003211561623,
      "grad_norm": 0.3532969355583191,
      "learning_rate": 7.561621838619029e-05,
      "loss": 0.3315,
      "step": 23250
    },
    {
      "epoch": 3.1178910745349926,
      "grad_norm": 0.7153186202049255,
      "learning_rate": 7.534858825103707e-05,
      "loss": 0.349,
      "step": 23300
    },
    {
      "epoch": 3.124581827913823,
      "grad_norm": 0.1777375340461731,
      "learning_rate": 7.508095811588385e-05,
      "loss": 0.3423,
      "step": 23350
    },
    {
      "epoch": 3.1312725812926536,
      "grad_norm": 0.2251434177160263,
      "learning_rate": 7.481332798073063e-05,
      "loss": 0.3347,
      "step": 23400
    },
    {
      "epoch": 3.137963334671484,
      "grad_norm": 0.17112231254577637,
      "learning_rate": 7.454569784557741e-05,
      "loss": 0.3433,
      "step": 23450
    },
    {
      "epoch": 3.1446540880503147,
      "grad_norm": 0.5179905295372009,
      "learning_rate": 7.427806771042419e-05,
      "loss": 0.3665,
      "step": 23500
    },
    {
      "epoch": 3.151344841429145,
      "grad_norm": 0.6973052024841309,
      "learning_rate": 7.401043757527097e-05,
      "loss": 0.3831,
      "step": 23550
    },
    {
      "epoch": 3.1580355948079752,
      "grad_norm": 0.2033800333738327,
      "learning_rate": 7.374280744011775e-05,
      "loss": 0.3519,
      "step": 23600
    },
    {
      "epoch": 3.164726348186806,
      "grad_norm": 0.24206149578094482,
      "learning_rate": 7.347517730496454e-05,
      "loss": 0.3666,
      "step": 23650
    },
    {
      "epoch": 3.1714171015656363,
      "grad_norm": 0.2501700520515442,
      "learning_rate": 7.320754716981132e-05,
      "loss": 0.35,
      "step": 23700
    },
    {
      "epoch": 3.1781078549444666,
      "grad_norm": 0.38581520318984985,
      "learning_rate": 7.29399170346581e-05,
      "loss": 0.3564,
      "step": 23750
    },
    {
      "epoch": 3.1847986083232973,
      "grad_norm": 0.1968478560447693,
      "learning_rate": 7.267228689950488e-05,
      "loss": 0.3535,
      "step": 23800
    },
    {
      "epoch": 3.1914893617021276,
      "grad_norm": 0.6417688131332397,
      "learning_rate": 7.240465676435168e-05,
      "loss": 0.3985,
      "step": 23850
    },
    {
      "epoch": 3.198180115080958,
      "grad_norm": 0.6586573719978333,
      "learning_rate": 7.213702662919846e-05,
      "loss": 0.3555,
      "step": 23900
    },
    {
      "epoch": 3.2048708684597886,
      "grad_norm": 0.30921345949172974,
      "learning_rate": 7.186939649404524e-05,
      "loss": 0.3552,
      "step": 23950
    },
    {
      "epoch": 3.211561621838619,
      "grad_norm": 0.3520262837409973,
      "learning_rate": 7.160176635889202e-05,
      "loss": 0.3432,
      "step": 24000
    },
    {
      "epoch": 3.2182523752174497,
      "grad_norm": 0.189041867852211,
      "learning_rate": 7.13341362237388e-05,
      "loss": 0.3429,
      "step": 24050
    },
    {
      "epoch": 3.22494312859628,
      "grad_norm": 0.24816487729549408,
      "learning_rate": 7.106650608858558e-05,
      "loss": 0.3788,
      "step": 24100
    },
    {
      "epoch": 3.2316338819751103,
      "grad_norm": 0.6731555461883545,
      "learning_rate": 7.079887595343237e-05,
      "loss": 0.3515,
      "step": 24150
    },
    {
      "epoch": 3.238324635353941,
      "grad_norm": 0.28289657831192017,
      "learning_rate": 7.053124581827915e-05,
      "loss": 0.3498,
      "step": 24200
    },
    {
      "epoch": 3.2450153887327713,
      "grad_norm": 0.25865086913108826,
      "learning_rate": 7.026361568312593e-05,
      "loss": 0.3329,
      "step": 24250
    },
    {
      "epoch": 3.2517061421116016,
      "grad_norm": 0.6468029022216797,
      "learning_rate": 6.999598554797271e-05,
      "loss": 0.3491,
      "step": 24300
    },
    {
      "epoch": 3.2583968954904323,
      "grad_norm": 0.6936389803886414,
      "learning_rate": 6.972835541281949e-05,
      "loss": 0.3591,
      "step": 24350
    },
    {
      "epoch": 3.2650876488692626,
      "grad_norm": 0.31565672159194946,
      "learning_rate": 6.946072527766627e-05,
      "loss": 0.3383,
      "step": 24400
    },
    {
      "epoch": 3.271778402248093,
      "grad_norm": 0.6120352745056152,
      "learning_rate": 6.919309514251305e-05,
      "loss": 0.36,
      "step": 24450
    },
    {
      "epoch": 3.2784691556269236,
      "grad_norm": 0.26141366362571716,
      "learning_rate": 6.892546500735983e-05,
      "loss": 0.3675,
      "step": 24500
    },
    {
      "epoch": 3.285159909005754,
      "grad_norm": 0.22056102752685547,
      "learning_rate": 6.865783487220662e-05,
      "loss": 0.3715,
      "step": 24550
    },
    {
      "epoch": 3.2918506623845847,
      "grad_norm": 0.34419962763786316,
      "learning_rate": 6.83902047370534e-05,
      "loss": 0.3855,
      "step": 24600
    },
    {
      "epoch": 3.298541415763415,
      "grad_norm": 0.30597153306007385,
      "learning_rate": 6.812257460190018e-05,
      "loss": 0.321,
      "step": 24650
    },
    {
      "epoch": 3.3052321691422453,
      "grad_norm": 0.265045702457428,
      "learning_rate": 6.785494446674696e-05,
      "loss": 0.3588,
      "step": 24700
    },
    {
      "epoch": 3.311922922521076,
      "grad_norm": 1.0078871250152588,
      "learning_rate": 6.758731433159374e-05,
      "loss": 0.346,
      "step": 24750
    },
    {
      "epoch": 3.3186136758999063,
      "grad_norm": 0.6075974702835083,
      "learning_rate": 6.731968419644052e-05,
      "loss": 0.371,
      "step": 24800
    },
    {
      "epoch": 3.3253044292787366,
      "grad_norm": 0.5116586685180664,
      "learning_rate": 6.705740666399036e-05,
      "loss": 0.349,
      "step": 24850
    },
    {
      "epoch": 3.3319951826575673,
      "grad_norm": 0.3708692193031311,
      "learning_rate": 6.678977652883715e-05,
      "loss": 0.3531,
      "step": 24900
    },
    {
      "epoch": 3.3386859360363976,
      "grad_norm": 0.6163002848625183,
      "learning_rate": 6.652214639368394e-05,
      "loss": 0.3461,
      "step": 24950
    },
    {
      "epoch": 3.345376689415228,
      "grad_norm": 0.7408391833305359,
      "learning_rate": 6.625451625853072e-05,
      "loss": 0.3417,
      "step": 25000
    },
    {
      "epoch": 3.3520674427940587,
      "grad_norm": 0.4737233519554138,
      "learning_rate": 6.59868861233775e-05,
      "loss": 0.3615,
      "step": 25050
    },
    {
      "epoch": 3.358758196172889,
      "grad_norm": 0.37881624698638916,
      "learning_rate": 6.571925598822428e-05,
      "loss": 0.3433,
      "step": 25100
    },
    {
      "epoch": 3.3654489495517197,
      "grad_norm": 0.2223706692457199,
      "learning_rate": 6.545162585307106e-05,
      "loss": 0.3733,
      "step": 25150
    },
    {
      "epoch": 3.37213970293055,
      "grad_norm": 0.3892666697502136,
      "learning_rate": 6.518399571791784e-05,
      "loss": 0.3467,
      "step": 25200
    },
    {
      "epoch": 3.3788304563093803,
      "grad_norm": 1.0215563774108887,
      "learning_rate": 6.491636558276462e-05,
      "loss": 0.3417,
      "step": 25250
    },
    {
      "epoch": 3.385521209688211,
      "grad_norm": 0.3770616054534912,
      "learning_rate": 6.46487354476114e-05,
      "loss": 0.3603,
      "step": 25300
    },
    {
      "epoch": 3.3922119630670413,
      "grad_norm": 0.22973373532295227,
      "learning_rate": 6.43811053124582e-05,
      "loss": 0.3639,
      "step": 25350
    },
    {
      "epoch": 3.398902716445872,
      "grad_norm": 0.31705835461616516,
      "learning_rate": 6.411347517730498e-05,
      "loss": 0.3656,
      "step": 25400
    },
    {
      "epoch": 3.4055934698247023,
      "grad_norm": 0.20213592052459717,
      "learning_rate": 6.384584504215176e-05,
      "loss": 0.3671,
      "step": 25450
    },
    {
      "epoch": 3.4122842232035326,
      "grad_norm": 0.7415368556976318,
      "learning_rate": 6.357821490699854e-05,
      "loss": 0.3726,
      "step": 25500
    },
    {
      "epoch": 3.418974976582363,
      "grad_norm": 0.517408549785614,
      "learning_rate": 6.331058477184532e-05,
      "loss": 0.3747,
      "step": 25550
    },
    {
      "epoch": 3.4256657299611937,
      "grad_norm": 0.2908784747123718,
      "learning_rate": 6.30429546366921e-05,
      "loss": 0.3407,
      "step": 25600
    },
    {
      "epoch": 3.432356483340024,
      "grad_norm": 0.33734938502311707,
      "learning_rate": 6.277532450153887e-05,
      "loss": 0.3384,
      "step": 25650
    },
    {
      "epoch": 3.4390472367188547,
      "grad_norm": 0.3480285108089447,
      "learning_rate": 6.250769436638565e-05,
      "loss": 0.3693,
      "step": 25700
    },
    {
      "epoch": 3.445737990097685,
      "grad_norm": 0.7337917685508728,
      "learning_rate": 6.224006423123245e-05,
      "loss": 0.342,
      "step": 25750
    },
    {
      "epoch": 3.4524287434765153,
      "grad_norm": 0.2727845311164856,
      "learning_rate": 6.197243409607923e-05,
      "loss": 0.3654,
      "step": 25800
    },
    {
      "epoch": 3.459119496855346,
      "grad_norm": 0.25947871804237366,
      "learning_rate": 6.170480396092601e-05,
      "loss": 0.3387,
      "step": 25850
    },
    {
      "epoch": 3.4658102502341763,
      "grad_norm": 0.35128268599510193,
      "learning_rate": 6.143717382577279e-05,
      "loss": 0.3141,
      "step": 25900
    },
    {
      "epoch": 3.472501003613007,
      "grad_norm": 0.26149606704711914,
      "learning_rate": 6.116954369061957e-05,
      "loss": 0.3447,
      "step": 25950
    },
    {
      "epoch": 3.4791917569918374,
      "grad_norm": 0.3215799033641815,
      "learning_rate": 6.090191355546635e-05,
      "loss": 0.3615,
      "step": 26000
    },
    {
      "epoch": 3.4858825103706677,
      "grad_norm": 0.6314677000045776,
      "learning_rate": 6.0634283420313134e-05,
      "loss": 0.3555,
      "step": 26050
    },
    {
      "epoch": 3.492573263749498,
      "grad_norm": 0.4843919277191162,
      "learning_rate": 6.0366653285159914e-05,
      "loss": 0.3268,
      "step": 26100
    },
    {
      "epoch": 3.4992640171283287,
      "grad_norm": 0.3228873610496521,
      "learning_rate": 6.0099023150006694e-05,
      "loss": 0.3314,
      "step": 26150
    },
    {
      "epoch": 3.505954770507159,
      "grad_norm": 0.20970207452774048,
      "learning_rate": 5.9831393014853474e-05,
      "loss": 0.3649,
      "step": 26200
    },
    {
      "epoch": 3.5126455238859897,
      "grad_norm": 0.7157613039016724,
      "learning_rate": 5.956376287970026e-05,
      "loss": 0.3446,
      "step": 26250
    },
    {
      "epoch": 3.51933627726482,
      "grad_norm": 0.21495321393013,
      "learning_rate": 5.929613274454704e-05,
      "loss": 0.3736,
      "step": 26300
    },
    {
      "epoch": 3.5260270306436503,
      "grad_norm": 0.27416110038757324,
      "learning_rate": 5.902850260939382e-05,
      "loss": 0.3816,
      "step": 26350
    },
    {
      "epoch": 3.532717784022481,
      "grad_norm": 0.3660842478275299,
      "learning_rate": 5.87608724742406e-05,
      "loss": 0.3506,
      "step": 26400
    },
    {
      "epoch": 3.5394085374013113,
      "grad_norm": 0.5146440267562866,
      "learning_rate": 5.8493242339087386e-05,
      "loss": 0.377,
      "step": 26450
    },
    {
      "epoch": 3.546099290780142,
      "grad_norm": 0.297872930765152,
      "learning_rate": 5.8225612203934166e-05,
      "loss": 0.344,
      "step": 26500
    },
    {
      "epoch": 3.5527900441589724,
      "grad_norm": 0.1776810735464096,
      "learning_rate": 5.7957982068780946e-05,
      "loss": 0.3324,
      "step": 26550
    },
    {
      "epoch": 3.5594807975378027,
      "grad_norm": 0.4025779962539673,
      "learning_rate": 5.7690351933627726e-05,
      "loss": 0.3381,
      "step": 26600
    },
    {
      "epoch": 3.566171550916633,
      "grad_norm": 0.27757641673088074,
      "learning_rate": 5.742272179847451e-05,
      "loss": 0.3604,
      "step": 26650
    },
    {
      "epoch": 3.5728623042954637,
      "grad_norm": 0.2652784585952759,
      "learning_rate": 5.715509166332129e-05,
      "loss": 0.3436,
      "step": 26700
    },
    {
      "epoch": 3.579553057674294,
      "grad_norm": 0.2206634283065796,
      "learning_rate": 5.688746152816807e-05,
      "loss": 0.3408,
      "step": 26750
    },
    {
      "epoch": 3.5862438110531247,
      "grad_norm": 0.5418571829795837,
      "learning_rate": 5.661983139301485e-05,
      "loss": 0.3641,
      "step": 26800
    },
    {
      "epoch": 3.592934564431955,
      "grad_norm": 0.31862974166870117,
      "learning_rate": 5.635220125786164e-05,
      "loss": 0.31,
      "step": 26850
    },
    {
      "epoch": 3.5996253178107853,
      "grad_norm": 0.39505884051322937,
      "learning_rate": 5.608457112270842e-05,
      "loss": 0.3661,
      "step": 26900
    },
    {
      "epoch": 3.606316071189616,
      "grad_norm": 0.23907940089702606,
      "learning_rate": 5.58169409875552e-05,
      "loss": 0.3094,
      "step": 26950
    },
    {
      "epoch": 3.6130068245684464,
      "grad_norm": 0.31134095788002014,
      "learning_rate": 5.554931085240198e-05,
      "loss": 0.3425,
      "step": 27000
    },
    {
      "epoch": 3.619697577947277,
      "grad_norm": 0.38639137148857117,
      "learning_rate": 5.5281680717248765e-05,
      "loss": 0.3567,
      "step": 27050
    },
    {
      "epoch": 3.6263883313261074,
      "grad_norm": 0.32597699761390686,
      "learning_rate": 5.5014050582095545e-05,
      "loss": 0.334,
      "step": 27100
    },
    {
      "epoch": 3.6330790847049377,
      "grad_norm": 0.30501410365104675,
      "learning_rate": 5.4746420446942325e-05,
      "loss": 0.3246,
      "step": 27150
    },
    {
      "epoch": 3.639769838083768,
      "grad_norm": 0.3273744285106659,
      "learning_rate": 5.4478790311789105e-05,
      "loss": 0.3375,
      "step": 27200
    },
    {
      "epoch": 3.6464605914625987,
      "grad_norm": 0.44743597507476807,
      "learning_rate": 5.421116017663589e-05,
      "loss": 0.4001,
      "step": 27250
    },
    {
      "epoch": 3.653151344841429,
      "grad_norm": 1.615809440612793,
      "learning_rate": 5.394353004148267e-05,
      "loss": 0.4041,
      "step": 27300
    },
    {
      "epoch": 3.6598420982202597,
      "grad_norm": 1.030531644821167,
      "learning_rate": 5.367589990632945e-05,
      "loss": 0.3626,
      "step": 27350
    },
    {
      "epoch": 3.66653285159909,
      "grad_norm": 0.6477115750312805,
      "learning_rate": 5.340826977117623e-05,
      "loss": 0.38,
      "step": 27400
    },
    {
      "epoch": 3.6732236049779203,
      "grad_norm": 0.33064019680023193,
      "learning_rate": 5.314063963602302e-05,
      "loss": 0.3733,
      "step": 27450
    },
    {
      "epoch": 3.679914358356751,
      "grad_norm": 0.3073388338088989,
      "learning_rate": 5.28730095008698e-05,
      "loss": 0.372,
      "step": 27500
    },
    {
      "epoch": 3.6866051117355814,
      "grad_norm": 0.47240155935287476,
      "learning_rate": 5.260537936571658e-05,
      "loss": 0.3599,
      "step": 27550
    },
    {
      "epoch": 3.693295865114412,
      "grad_norm": 0.46524330973625183,
      "learning_rate": 5.233774923056336e-05,
      "loss": 0.3442,
      "step": 27600
    },
    {
      "epoch": 3.6999866184932424,
      "grad_norm": 1.019108533859253,
      "learning_rate": 5.2070119095410144e-05,
      "loss": 0.3674,
      "step": 27650
    },
    {
      "epoch": 3.7066773718720727,
      "grad_norm": 0.28651365637779236,
      "learning_rate": 5.1802488960256923e-05,
      "loss": 0.3638,
      "step": 27700
    },
    {
      "epoch": 3.713368125250903,
      "grad_norm": 0.5293595194816589,
      "learning_rate": 5.15348588251037e-05,
      "loss": 0.3422,
      "step": 27750
    },
    {
      "epoch": 3.7200588786297337,
      "grad_norm": 0.19594421982765198,
      "learning_rate": 5.126722868995048e-05,
      "loss": 0.3436,
      "step": 27800
    },
    {
      "epoch": 3.726749632008564,
      "grad_norm": 0.32284265756607056,
      "learning_rate": 5.099959855479727e-05,
      "loss": 0.3623,
      "step": 27850
    },
    {
      "epoch": 3.7334403853873948,
      "grad_norm": 0.2068096548318863,
      "learning_rate": 5.073196841964405e-05,
      "loss": 0.3693,
      "step": 27900
    },
    {
      "epoch": 3.740131138766225,
      "grad_norm": 0.18807809054851532,
      "learning_rate": 5.046433828449083e-05,
      "loss": 0.3483,
      "step": 27950
    },
    {
      "epoch": 3.7468218921450553,
      "grad_norm": 0.471095472574234,
      "learning_rate": 5.019670814933761e-05,
      "loss": 0.3187,
      "step": 28000
    },
    {
      "epoch": 3.753512645523886,
      "grad_norm": 0.5343185663223267,
      "learning_rate": 4.99290780141844e-05,
      "loss": 0.3605,
      "step": 28050
    },
    {
      "epoch": 3.7602033989027164,
      "grad_norm": 0.24217063188552856,
      "learning_rate": 4.966144787903118e-05,
      "loss": 0.359,
      "step": 28100
    },
    {
      "epoch": 3.766894152281547,
      "grad_norm": 0.48635873198509216,
      "learning_rate": 4.939381774387796e-05,
      "loss": 0.3685,
      "step": 28150
    },
    {
      "epoch": 3.7735849056603774,
      "grad_norm": 0.3339529037475586,
      "learning_rate": 4.912618760872474e-05,
      "loss": 0.3328,
      "step": 28200
    },
    {
      "epoch": 3.7802756590392077,
      "grad_norm": 0.3359795808792114,
      "learning_rate": 4.885855747357153e-05,
      "loss": 0.3304,
      "step": 28250
    },
    {
      "epoch": 3.786966412418038,
      "grad_norm": 0.22737973928451538,
      "learning_rate": 4.859092733841831e-05,
      "loss": 0.3471,
      "step": 28300
    },
    {
      "epoch": 3.7936571657968687,
      "grad_norm": 0.24981388449668884,
      "learning_rate": 4.832329720326509e-05,
      "loss": 0.3797,
      "step": 28350
    },
    {
      "epoch": 3.800347919175699,
      "grad_norm": 0.33721911907196045,
      "learning_rate": 4.805566706811187e-05,
      "loss": 0.3297,
      "step": 28400
    },
    {
      "epoch": 3.8070386725545298,
      "grad_norm": 0.31637075543403625,
      "learning_rate": 4.7788036932958655e-05,
      "loss": 0.3657,
      "step": 28450
    },
    {
      "epoch": 3.81372942593336,
      "grad_norm": 0.15107929706573486,
      "learning_rate": 4.7520406797805435e-05,
      "loss": 0.3544,
      "step": 28500
    },
    {
      "epoch": 3.8204201793121904,
      "grad_norm": 0.24382400512695312,
      "learning_rate": 4.7252776662652215e-05,
      "loss": 0.3671,
      "step": 28550
    },
    {
      "epoch": 3.827110932691021,
      "grad_norm": 0.3819771111011505,
      "learning_rate": 4.6985146527498995e-05,
      "loss": 0.3434,
      "step": 28600
    },
    {
      "epoch": 3.8338016860698514,
      "grad_norm": 0.7497795224189758,
      "learning_rate": 4.671751639234578e-05,
      "loss": 0.3619,
      "step": 28650
    },
    {
      "epoch": 3.840492439448682,
      "grad_norm": 0.42167308926582336,
      "learning_rate": 4.644988625719256e-05,
      "loss": 0.3288,
      "step": 28700
    },
    {
      "epoch": 3.8471831928275124,
      "grad_norm": 0.5839011073112488,
      "learning_rate": 4.618225612203934e-05,
      "loss": 0.3343,
      "step": 28750
    },
    {
      "epoch": 3.8538739462063427,
      "grad_norm": 0.5099455714225769,
      "learning_rate": 4.591462598688612e-05,
      "loss": 0.3577,
      "step": 28800
    },
    {
      "epoch": 3.8605646995851735,
      "grad_norm": 0.3792499303817749,
      "learning_rate": 4.564699585173291e-05,
      "loss": 0.3373,
      "step": 28850
    },
    {
      "epoch": 3.8672554529640037,
      "grad_norm": 0.2974012494087219,
      "learning_rate": 4.5379365716579694e-05,
      "loss": 0.3578,
      "step": 28900
    },
    {
      "epoch": 3.873946206342834,
      "grad_norm": 0.2926502823829651,
      "learning_rate": 4.5111735581426474e-05,
      "loss": 0.3268,
      "step": 28950
    },
    {
      "epoch": 3.880636959721665,
      "grad_norm": 0.6791081428527832,
      "learning_rate": 4.4844105446273254e-05,
      "loss": 0.3894,
      "step": 29000
    },
    {
      "epoch": 3.887327713100495,
      "grad_norm": 0.43743494153022766,
      "learning_rate": 4.4576475311120034e-05,
      "loss": 0.3678,
      "step": 29050
    },
    {
      "epoch": 3.8940184664793254,
      "grad_norm": 0.28794851899147034,
      "learning_rate": 4.431419777866988e-05,
      "loss": 0.3414,
      "step": 29100
    },
    {
      "epoch": 3.900709219858156,
      "grad_norm": 0.5767615437507629,
      "learning_rate": 4.404656764351666e-05,
      "loss": 0.3894,
      "step": 29150
    },
    {
      "epoch": 3.9073999732369864,
      "grad_norm": 0.3542620837688446,
      "learning_rate": 4.377893750836344e-05,
      "loss": 0.3278,
      "step": 29200
    },
    {
      "epoch": 3.914090726615817,
      "grad_norm": 0.22313660383224487,
      "learning_rate": 4.351130737321022e-05,
      "loss": 0.3447,
      "step": 29250
    },
    {
      "epoch": 3.9207814799946474,
      "grad_norm": 0.6752740144729614,
      "learning_rate": 4.324367723805701e-05,
      "loss": 0.3722,
      "step": 29300
    },
    {
      "epoch": 3.9274722333734777,
      "grad_norm": 0.2210097759962082,
      "learning_rate": 4.297604710290379e-05,
      "loss": 0.3184,
      "step": 29350
    },
    {
      "epoch": 3.9341629867523085,
      "grad_norm": 0.18830235302448273,
      "learning_rate": 4.270841696775057e-05,
      "loss": 0.3481,
      "step": 29400
    },
    {
      "epoch": 3.9408537401311388,
      "grad_norm": 0.35997122526168823,
      "learning_rate": 4.244078683259735e-05,
      "loss": 0.3737,
      "step": 29450
    },
    {
      "epoch": 3.9475444935099695,
      "grad_norm": 0.3348483145236969,
      "learning_rate": 4.2173156697444135e-05,
      "loss": 0.3739,
      "step": 29500
    },
    {
      "epoch": 3.9542352468888,
      "grad_norm": 0.24024765193462372,
      "learning_rate": 4.1905526562290914e-05,
      "loss": 0.3932,
      "step": 29550
    },
    {
      "epoch": 3.96092600026763,
      "grad_norm": 0.35058534145355225,
      "learning_rate": 4.1637896427137694e-05,
      "loss": 0.3783,
      "step": 29600
    },
    {
      "epoch": 3.9676167536464604,
      "grad_norm": 0.4507204294204712,
      "learning_rate": 4.1370266291984474e-05,
      "loss": 0.3524,
      "step": 29650
    },
    {
      "epoch": 3.974307507025291,
      "grad_norm": 0.5160118341445923,
      "learning_rate": 4.110263615683126e-05,
      "loss": 0.3455,
      "step": 29700
    },
    {
      "epoch": 3.9809982604041214,
      "grad_norm": 0.3933923542499542,
      "learning_rate": 4.083500602167804e-05,
      "loss": 0.3868,
      "step": 29750
    },
    {
      "epoch": 3.987689013782952,
      "grad_norm": 0.5032134056091309,
      "learning_rate": 4.056737588652482e-05,
      "loss": 0.3424,
      "step": 29800
    },
    {
      "epoch": 3.9943797671617824,
      "grad_norm": 0.27688542008399963,
      "learning_rate": 4.02997457513716e-05,
      "loss": 0.3131,
      "step": 29850
    },
    {
      "epoch": 4.001070520540613,
      "grad_norm": 0.4402802884578705,
      "learning_rate": 4.0032115616218394e-05,
      "loss": 0.3819,
      "step": 29900
    },
    {
      "epoch": 4.007761273919443,
      "grad_norm": 0.2688239514827728,
      "learning_rate": 3.9764485481065174e-05,
      "loss": 0.3513,
      "step": 29950
    },
    {
      "epoch": 4.014452027298274,
      "grad_norm": 0.18589307367801666,
      "learning_rate": 3.9496855345911953e-05,
      "loss": 0.3334,
      "step": 30000
    },
    {
      "epoch": 4.0211427806771045,
      "grad_norm": 0.22118109464645386,
      "learning_rate": 3.922922521075873e-05,
      "loss": 0.3437,
      "step": 30050
    },
    {
      "epoch": 4.027833534055935,
      "grad_norm": 0.4726925194263458,
      "learning_rate": 3.896159507560552e-05,
      "loss": 0.3475,
      "step": 30100
    },
    {
      "epoch": 4.034524287434765,
      "grad_norm": 0.23524686694145203,
      "learning_rate": 3.86939649404523e-05,
      "loss": 0.3707,
      "step": 30150
    },
    {
      "epoch": 4.041215040813595,
      "grad_norm": 0.2814692556858063,
      "learning_rate": 3.842633480529908e-05,
      "loss": 0.3216,
      "step": 30200
    },
    {
      "epoch": 4.047905794192426,
      "grad_norm": 0.3870505690574646,
      "learning_rate": 3.815870467014586e-05,
      "loss": 0.332,
      "step": 30250
    },
    {
      "epoch": 4.054596547571257,
      "grad_norm": 0.5659789443016052,
      "learning_rate": 3.7891074534992646e-05,
      "loss": 0.3412,
      "step": 30300
    },
    {
      "epoch": 4.061287300950087,
      "grad_norm": 0.16289280354976654,
      "learning_rate": 3.7623444399839426e-05,
      "loss": 0.3462,
      "step": 30350
    },
    {
      "epoch": 4.0679780543289175,
      "grad_norm": 1.0083060264587402,
      "learning_rate": 3.7355814264686206e-05,
      "loss": 0.3404,
      "step": 30400
    },
    {
      "epoch": 4.074668807707748,
      "grad_norm": 0.3752642273902893,
      "learning_rate": 3.7088184129532986e-05,
      "loss": 0.3706,
      "step": 30450
    },
    {
      "epoch": 4.081359561086578,
      "grad_norm": 0.8366803526878357,
      "learning_rate": 3.682055399437977e-05,
      "loss": 0.3664,
      "step": 30500
    },
    {
      "epoch": 4.088050314465409,
      "grad_norm": 0.6572714447975159,
      "learning_rate": 3.655292385922655e-05,
      "loss": 0.3606,
      "step": 30550
    },
    {
      "epoch": 4.0947410678442395,
      "grad_norm": 0.2700652480125427,
      "learning_rate": 3.628529372407333e-05,
      "loss": 0.3508,
      "step": 30600
    },
    {
      "epoch": 4.10143182122307,
      "grad_norm": 0.29703953862190247,
      "learning_rate": 3.601766358892011e-05,
      "loss": 0.3412,
      "step": 30650
    },
    {
      "epoch": 4.1081225746019,
      "grad_norm": 0.3882814347743988,
      "learning_rate": 3.57500334537669e-05,
      "loss": 0.3285,
      "step": 30700
    },
    {
      "epoch": 4.11481332798073,
      "grad_norm": 0.4095185697078705,
      "learning_rate": 3.548240331861368e-05,
      "loss": 0.3491,
      "step": 30750
    },
    {
      "epoch": 4.121504081359561,
      "grad_norm": 0.2974790632724762,
      "learning_rate": 3.521477318346046e-05,
      "loss": 0.3545,
      "step": 30800
    },
    {
      "epoch": 4.128194834738392,
      "grad_norm": 0.4816540479660034,
      "learning_rate": 3.494714304830724e-05,
      "loss": 0.3277,
      "step": 30850
    },
    {
      "epoch": 4.134885588117222,
      "grad_norm": 0.34309616684913635,
      "learning_rate": 3.4679512913154025e-05,
      "loss": 0.3508,
      "step": 30900
    },
    {
      "epoch": 4.1415763414960525,
      "grad_norm": 0.2820379436016083,
      "learning_rate": 3.4411882778000805e-05,
      "loss": 0.3539,
      "step": 30950
    },
    {
      "epoch": 4.148267094874883,
      "grad_norm": 0.45708316564559937,
      "learning_rate": 3.4144252642847585e-05,
      "loss": 0.3514,
      "step": 31000
    },
    {
      "epoch": 4.154957848253713,
      "grad_norm": 0.25241535902023315,
      "learning_rate": 3.3876622507694364e-05,
      "loss": 0.3227,
      "step": 31050
    },
    {
      "epoch": 4.161648601632544,
      "grad_norm": 0.21896781027317047,
      "learning_rate": 3.360899237254115e-05,
      "loss": 0.3492,
      "step": 31100
    },
    {
      "epoch": 4.1683393550113745,
      "grad_norm": 0.36624616384506226,
      "learning_rate": 3.334136223738793e-05,
      "loss": 0.3474,
      "step": 31150
    },
    {
      "epoch": 4.175030108390205,
      "grad_norm": 0.5256267786026001,
      "learning_rate": 3.307373210223471e-05,
      "loss": 0.3912,
      "step": 31200
    },
    {
      "epoch": 4.181720861769035,
      "grad_norm": 0.1812153458595276,
      "learning_rate": 3.280610196708149e-05,
      "loss": 0.3365,
      "step": 31250
    },
    {
      "epoch": 4.188411615147865,
      "grad_norm": 0.4654294550418854,
      "learning_rate": 3.2543824434631346e-05,
      "loss": 0.3943,
      "step": 31300
    },
    {
      "epoch": 4.195102368526696,
      "grad_norm": 0.21981407701969147,
      "learning_rate": 3.2276194299478126e-05,
      "loss": 0.3099,
      "step": 31350
    },
    {
      "epoch": 4.201793121905527,
      "grad_norm": 0.34362125396728516,
      "learning_rate": 3.201391676702797e-05,
      "loss": 0.3389,
      "step": 31400
    },
    {
      "epoch": 4.208483875284357,
      "grad_norm": 0.3349195420742035,
      "learning_rate": 3.174628663187475e-05,
      "loss": 0.3481,
      "step": 31450
    },
    {
      "epoch": 4.2151746286631875,
      "grad_norm": 0.3565491735935211,
      "learning_rate": 3.1478656496721534e-05,
      "loss": 0.3217,
      "step": 31500
    },
    {
      "epoch": 4.221865382042018,
      "grad_norm": 0.36424770951271057,
      "learning_rate": 3.1211026361568313e-05,
      "loss": 0.3779,
      "step": 31550
    },
    {
      "epoch": 4.228556135420848,
      "grad_norm": 0.24740278720855713,
      "learning_rate": 3.094339622641509e-05,
      "loss": 0.3405,
      "step": 31600
    },
    {
      "epoch": 4.235246888799679,
      "grad_norm": 0.7569743990898132,
      "learning_rate": 3.067576609126187e-05,
      "loss": 0.3453,
      "step": 31650
    },
    {
      "epoch": 4.2419376421785095,
      "grad_norm": 0.4244247376918793,
      "learning_rate": 3.0408135956108656e-05,
      "loss": 0.3245,
      "step": 31700
    },
    {
      "epoch": 4.24862839555734,
      "grad_norm": 0.15384216606616974,
      "learning_rate": 3.014050582095544e-05,
      "loss": 0.3462,
      "step": 31750
    },
    {
      "epoch": 4.25531914893617,
      "grad_norm": 0.24150753021240234,
      "learning_rate": 2.987287568580222e-05,
      "loss": 0.3512,
      "step": 31800
    },
    {
      "epoch": 4.262009902315,
      "grad_norm": 0.1907866895198822,
      "learning_rate": 2.9605245550649003e-05,
      "loss": 0.349,
      "step": 31850
    },
    {
      "epoch": 4.268700655693831,
      "grad_norm": 0.25828787684440613,
      "learning_rate": 2.9337615415495783e-05,
      "loss": 0.3058,
      "step": 31900
    },
    {
      "epoch": 4.275391409072662,
      "grad_norm": 0.27916279435157776,
      "learning_rate": 2.9069985280342566e-05,
      "loss": 0.3215,
      "step": 31950
    },
    {
      "epoch": 4.282082162451492,
      "grad_norm": 0.375797837972641,
      "learning_rate": 2.8802355145189346e-05,
      "loss": 0.3554,
      "step": 32000
    },
    {
      "epoch": 4.2887729158303225,
      "grad_norm": 0.7583380937576294,
      "learning_rate": 2.8534725010036136e-05,
      "loss": 0.391,
      "step": 32050
    },
    {
      "epoch": 4.295463669209153,
      "grad_norm": 0.7923060059547424,
      "learning_rate": 2.8267094874882916e-05,
      "loss": 0.3564,
      "step": 32100
    },
    {
      "epoch": 4.302154422587983,
      "grad_norm": 0.3791046142578125,
      "learning_rate": 2.79994647397297e-05,
      "loss": 0.33,
      "step": 32150
    },
    {
      "epoch": 4.308845175966814,
      "grad_norm": 0.3676614761352539,
      "learning_rate": 2.773183460457648e-05,
      "loss": 0.3242,
      "step": 32200
    },
    {
      "epoch": 4.315535929345645,
      "grad_norm": 0.25043830275535583,
      "learning_rate": 2.7464204469423262e-05,
      "loss": 0.348,
      "step": 32250
    },
    {
      "epoch": 4.322226682724475,
      "grad_norm": 1.4167689085006714,
      "learning_rate": 2.7196574334270042e-05,
      "loss": 0.3674,
      "step": 32300
    },
    {
      "epoch": 4.328917436103305,
      "grad_norm": 0.31073668599128723,
      "learning_rate": 2.6928944199116825e-05,
      "loss": 0.3467,
      "step": 32350
    },
    {
      "epoch": 4.335608189482135,
      "grad_norm": 0.1782335340976715,
      "learning_rate": 2.6661314063963605e-05,
      "loss": 0.3675,
      "step": 32400
    },
    {
      "epoch": 4.342298942860966,
      "grad_norm": 0.3661381006240845,
      "learning_rate": 2.6393683928810388e-05,
      "loss": 0.3305,
      "step": 32450
    },
    {
      "epoch": 4.348989696239797,
      "grad_norm": 0.3855118453502655,
      "learning_rate": 2.6126053793657168e-05,
      "loss": 0.3539,
      "step": 32500
    },
    {
      "epoch": 4.355680449618627,
      "grad_norm": 0.22866767644882202,
      "learning_rate": 2.585842365850395e-05,
      "loss": 0.3531,
      "step": 32550
    },
    {
      "epoch": 4.3623712029974575,
      "grad_norm": 0.4082297384738922,
      "learning_rate": 2.559079352335073e-05,
      "loss": 0.3283,
      "step": 32600
    },
    {
      "epoch": 4.369061956376288,
      "grad_norm": 0.5047287940979004,
      "learning_rate": 2.5323163388197514e-05,
      "loss": 0.3628,
      "step": 32650
    },
    {
      "epoch": 4.375752709755118,
      "grad_norm": 0.3079674243927002,
      "learning_rate": 2.5055533253044294e-05,
      "loss": 0.3769,
      "step": 32700
    },
    {
      "epoch": 4.382443463133949,
      "grad_norm": 0.27611589431762695,
      "learning_rate": 2.4787903117891077e-05,
      "loss": 0.3236,
      "step": 32750
    },
    {
      "epoch": 4.38913421651278,
      "grad_norm": 0.7636933922767639,
      "learning_rate": 2.4520272982737857e-05,
      "loss": 0.364,
      "step": 32800
    },
    {
      "epoch": 4.39582496989161,
      "grad_norm": 0.8933479189872742,
      "learning_rate": 2.425264284758464e-05,
      "loss": 0.3384,
      "step": 32850
    },
    {
      "epoch": 4.40251572327044,
      "grad_norm": 0.39474737644195557,
      "learning_rate": 2.398501271243142e-05,
      "loss": 0.3329,
      "step": 32900
    },
    {
      "epoch": 4.4092064766492705,
      "grad_norm": 0.16115275025367737,
      "learning_rate": 2.3717382577278204e-05,
      "loss": 0.3434,
      "step": 32950
    },
    {
      "epoch": 4.415897230028101,
      "grad_norm": 0.3986349403858185,
      "learning_rate": 2.3449752442124984e-05,
      "loss": 0.3459,
      "step": 33000
    },
    {
      "epoch": 4.422587983406932,
      "grad_norm": 0.31896254420280457,
      "learning_rate": 2.3182122306971767e-05,
      "loss": 0.3415,
      "step": 33050
    },
    {
      "epoch": 4.429278736785762,
      "grad_norm": 0.2920534312725067,
      "learning_rate": 2.2914492171818547e-05,
      "loss": 0.329,
      "step": 33100
    },
    {
      "epoch": 4.4359694901645925,
      "grad_norm": 0.5392966866493225,
      "learning_rate": 2.264686203666533e-05,
      "loss": 0.3354,
      "step": 33150
    },
    {
      "epoch": 4.442660243543423,
      "grad_norm": 0.5549496412277222,
      "learning_rate": 2.2379231901512113e-05,
      "loss": 0.3489,
      "step": 33200
    },
    {
      "epoch": 4.449350996922253,
      "grad_norm": 0.311117947101593,
      "learning_rate": 2.2111601766358893e-05,
      "loss": 0.3338,
      "step": 33250
    },
    {
      "epoch": 4.456041750301084,
      "grad_norm": 0.3643878698348999,
      "learning_rate": 2.1843971631205676e-05,
      "loss": 0.3441,
      "step": 33300
    },
    {
      "epoch": 4.462732503679915,
      "grad_norm": 0.7785785794258118,
      "learning_rate": 2.1576341496052456e-05,
      "loss": 0.348,
      "step": 33350
    },
    {
      "epoch": 4.469423257058745,
      "grad_norm": 0.3750267028808594,
      "learning_rate": 2.130871136089924e-05,
      "loss": 0.3473,
      "step": 33400
    },
    {
      "epoch": 4.476114010437575,
      "grad_norm": 0.2480626255273819,
      "learning_rate": 2.104108122574602e-05,
      "loss": 0.3454,
      "step": 33450
    },
    {
      "epoch": 4.4828047638164055,
      "grad_norm": 0.7378413081169128,
      "learning_rate": 2.0773451090592802e-05,
      "loss": 0.3864,
      "step": 33500
    },
    {
      "epoch": 4.489495517195236,
      "grad_norm": 0.5515304803848267,
      "learning_rate": 2.0505820955439582e-05,
      "loss": 0.3502,
      "step": 33550
    },
    {
      "epoch": 4.496186270574067,
      "grad_norm": 0.3610820174217224,
      "learning_rate": 2.0238190820286366e-05,
      "loss": 0.3447,
      "step": 33600
    },
    {
      "epoch": 4.502877023952897,
      "grad_norm": 0.2553093135356903,
      "learning_rate": 1.9970560685133145e-05,
      "loss": 0.3517,
      "step": 33650
    },
    {
      "epoch": 4.5095677773317275,
      "grad_norm": 0.3591345548629761,
      "learning_rate": 1.970293054997993e-05,
      "loss": 0.36,
      "step": 33700
    },
    {
      "epoch": 4.516258530710558,
      "grad_norm": 0.7187339067459106,
      "learning_rate": 1.943530041482671e-05,
      "loss": 0.3161,
      "step": 33750
    },
    {
      "epoch": 4.522949284089388,
      "grad_norm": 0.23478145897388458,
      "learning_rate": 1.9167670279673492e-05,
      "loss": 0.3279,
      "step": 33800
    },
    {
      "epoch": 4.529640037468219,
      "grad_norm": 0.3532135784626007,
      "learning_rate": 1.890004014452027e-05,
      "loss": 0.3595,
      "step": 33850
    },
    {
      "epoch": 4.53633079084705,
      "grad_norm": 1.085869312286377,
      "learning_rate": 1.8632410009367055e-05,
      "loss": 0.3557,
      "step": 33900
    },
    {
      "epoch": 4.54302154422588,
      "grad_norm": 0.28803905844688416,
      "learning_rate": 1.8364779874213835e-05,
      "loss": 0.3659,
      "step": 33950
    },
    {
      "epoch": 4.54971229760471,
      "grad_norm": 0.3495287001132965,
      "learning_rate": 1.809714973906062e-05,
      "loss": 0.3293,
      "step": 34000
    },
    {
      "epoch": 4.5564030509835405,
      "grad_norm": 0.3908097445964813,
      "learning_rate": 1.78295196039074e-05,
      "loss": 0.353,
      "step": 34050
    },
    {
      "epoch": 4.563093804362371,
      "grad_norm": 0.5601668357849121,
      "learning_rate": 1.7561889468754184e-05,
      "loss": 0.3293,
      "step": 34100
    },
    {
      "epoch": 4.569784557741202,
      "grad_norm": 0.3702540993690491,
      "learning_rate": 1.7299611936304026e-05,
      "loss": 0.3404,
      "step": 34150
    },
    {
      "epoch": 4.576475311120032,
      "grad_norm": 0.6453188061714172,
      "learning_rate": 1.703198180115081e-05,
      "loss": 0.3257,
      "step": 34200
    },
    {
      "epoch": 4.5831660644988625,
      "grad_norm": 0.1844983994960785,
      "learning_rate": 1.676435166599759e-05,
      "loss": 0.3844,
      "step": 34250
    },
    {
      "epoch": 4.589856817877693,
      "grad_norm": 0.4027215838432312,
      "learning_rate": 1.6496721530844376e-05,
      "loss": 0.359,
      "step": 34300
    },
    {
      "epoch": 4.596547571256523,
      "grad_norm": 0.41410064697265625,
      "learning_rate": 1.6229091395691156e-05,
      "loss": 0.3419,
      "step": 34350
    },
    {
      "epoch": 4.603238324635354,
      "grad_norm": 0.2626073956489563,
      "learning_rate": 1.596146126053794e-05,
      "loss": 0.3407,
      "step": 34400
    },
    {
      "epoch": 4.609929078014185,
      "grad_norm": 0.3562373220920563,
      "learning_rate": 1.569383112538472e-05,
      "loss": 0.3335,
      "step": 34450
    },
    {
      "epoch": 4.616619831393015,
      "grad_norm": 0.2782663404941559,
      "learning_rate": 1.5426200990231502e-05,
      "loss": 0.3383,
      "step": 34500
    },
    {
      "epoch": 4.623310584771845,
      "grad_norm": 0.40323877334594727,
      "learning_rate": 1.5158570855078283e-05,
      "loss": 0.3082,
      "step": 34550
    },
    {
      "epoch": 4.6300013381506755,
      "grad_norm": 0.362782746553421,
      "learning_rate": 1.4890940719925065e-05,
      "loss": 0.3269,
      "step": 34600
    },
    {
      "epoch": 4.636692091529506,
      "grad_norm": 0.5472759008407593,
      "learning_rate": 1.4623310584771847e-05,
      "loss": 0.3358,
      "step": 34650
    },
    {
      "epoch": 4.643382844908337,
      "grad_norm": 0.2675633430480957,
      "learning_rate": 1.4355680449618628e-05,
      "loss": 0.3374,
      "step": 34700
    },
    {
      "epoch": 4.650073598287167,
      "grad_norm": 0.19145889580249786,
      "learning_rate": 1.408805031446541e-05,
      "loss": 0.3101,
      "step": 34750
    },
    {
      "epoch": 4.656764351665998,
      "grad_norm": 0.20332832634449005,
      "learning_rate": 1.3820420179312191e-05,
      "loss": 0.3388,
      "step": 34800
    },
    {
      "epoch": 4.663455105044828,
      "grad_norm": 0.3381969928741455,
      "learning_rate": 1.3552790044158973e-05,
      "loss": 0.3379,
      "step": 34850
    },
    {
      "epoch": 4.670145858423658,
      "grad_norm": 0.43539467453956604,
      "learning_rate": 1.3285159909005754e-05,
      "loss": 0.3416,
      "step": 34900
    },
    {
      "epoch": 4.676836611802489,
      "grad_norm": 0.5144723057746887,
      "learning_rate": 1.3017529773852536e-05,
      "loss": 0.3415,
      "step": 34950
    },
    {
      "epoch": 4.68352736518132,
      "grad_norm": 0.4795868396759033,
      "learning_rate": 1.2749899638699317e-05,
      "loss": 0.3551,
      "step": 35000
    },
    {
      "epoch": 4.69021811856015,
      "grad_norm": 0.9326738119125366,
      "learning_rate": 1.24822695035461e-05,
      "loss": 0.361,
      "step": 35050
    },
    {
      "epoch": 4.69690887193898,
      "grad_norm": 0.4023174047470093,
      "learning_rate": 1.2214639368392882e-05,
      "loss": 0.3556,
      "step": 35100
    },
    {
      "epoch": 4.7035996253178105,
      "grad_norm": 0.20331420004367828,
      "learning_rate": 1.1947009233239664e-05,
      "loss": 0.3559,
      "step": 35150
    },
    {
      "epoch": 4.710290378696641,
      "grad_norm": 0.6332422494888306,
      "learning_rate": 1.1679379098086445e-05,
      "loss": 0.3361,
      "step": 35200
    },
    {
      "epoch": 4.716981132075472,
      "grad_norm": 0.9906761050224304,
      "learning_rate": 1.1411748962933227e-05,
      "loss": 0.3443,
      "step": 35250
    },
    {
      "epoch": 4.723671885454302,
      "grad_norm": 0.38787075877189636,
      "learning_rate": 1.1144118827780008e-05,
      "loss": 0.329,
      "step": 35300
    },
    {
      "epoch": 4.730362638833133,
      "grad_norm": 0.38196656107902527,
      "learning_rate": 1.087648869262679e-05,
      "loss": 0.3188,
      "step": 35350
    },
    {
      "epoch": 4.737053392211963,
      "grad_norm": 0.31770578026771545,
      "learning_rate": 1.0608858557473572e-05,
      "loss": 0.348,
      "step": 35400
    },
    {
      "epoch": 4.743744145590793,
      "grad_norm": 0.6356232762336731,
      "learning_rate": 1.0341228422320353e-05,
      "loss": 0.369,
      "step": 35450
    },
    {
      "epoch": 4.750434898969624,
      "grad_norm": 0.7224128246307373,
      "learning_rate": 1.0073598287167135e-05,
      "loss": 0.3315,
      "step": 35500
    },
    {
      "epoch": 4.757125652348455,
      "grad_norm": 0.46709904074668884,
      "learning_rate": 9.805968152013916e-06,
      "loss": 0.3451,
      "step": 35550
    },
    {
      "epoch": 4.763816405727285,
      "grad_norm": 0.4687424600124359,
      "learning_rate": 9.538338016860698e-06,
      "loss": 0.3339,
      "step": 35600
    },
    {
      "epoch": 4.770507159106115,
      "grad_norm": 0.4631120264530182,
      "learning_rate": 9.270707881707481e-06,
      "loss": 0.3359,
      "step": 35650
    },
    {
      "epoch": 4.7771979124849455,
      "grad_norm": 0.25482505559921265,
      "learning_rate": 9.003077746554263e-06,
      "loss": 0.3316,
      "step": 35700
    },
    {
      "epoch": 4.783888665863776,
      "grad_norm": 0.8933092951774597,
      "learning_rate": 8.735447611401044e-06,
      "loss": 0.3747,
      "step": 35750
    },
    {
      "epoch": 4.790579419242607,
      "grad_norm": 0.21081122756004333,
      "learning_rate": 8.467817476247826e-06,
      "loss": 0.3267,
      "step": 35800
    },
    {
      "epoch": 4.797270172621437,
      "grad_norm": 0.16258445382118225,
      "learning_rate": 8.200187341094607e-06,
      "loss": 0.3219,
      "step": 35850
    },
    {
      "epoch": 4.803960926000268,
      "grad_norm": 0.23751229047775269,
      "learning_rate": 7.932557205941389e-06,
      "loss": 0.3673,
      "step": 35900
    },
    {
      "epoch": 4.810651679379098,
      "grad_norm": 0.3298571705818176,
      "learning_rate": 7.66492707078817e-06,
      "loss": 0.3657,
      "step": 35950
    },
    {
      "epoch": 4.817342432757928,
      "grad_norm": 0.2848622798919678,
      "learning_rate": 7.397296935634952e-06,
      "loss": 0.3472,
      "step": 36000
    },
    {
      "epoch": 4.824033186136759,
      "grad_norm": 0.37372100353240967,
      "learning_rate": 7.129666800481735e-06,
      "loss": 0.3397,
      "step": 36050
    },
    {
      "epoch": 4.83072393951559,
      "grad_norm": 0.20299316942691803,
      "learning_rate": 6.862036665328517e-06,
      "loss": 0.3283,
      "step": 36100
    },
    {
      "epoch": 4.83741469289442,
      "grad_norm": 0.39912688732147217,
      "learning_rate": 6.594406530175298e-06,
      "loss": 0.3314,
      "step": 36150
    },
    {
      "epoch": 4.84410544627325,
      "grad_norm": 0.555221438407898,
      "learning_rate": 6.32677639502208e-06,
      "loss": 0.3462,
      "step": 36200
    },
    {
      "epoch": 4.8507961996520805,
      "grad_norm": 0.19267548620700836,
      "learning_rate": 6.059146259868861e-06,
      "loss": 0.326,
      "step": 36250
    },
    {
      "epoch": 4.857486953030911,
      "grad_norm": 0.4076478183269501,
      "learning_rate": 5.791516124715643e-06,
      "loss": 0.3265,
      "step": 36300
    },
    {
      "epoch": 4.864177706409742,
      "grad_norm": 0.3759772479534149,
      "learning_rate": 5.523885989562425e-06,
      "loss": 0.3178,
      "step": 36350
    },
    {
      "epoch": 4.870868459788572,
      "grad_norm": 0.11987201124429703,
      "learning_rate": 5.256255854409207e-06,
      "loss": 0.3484,
      "step": 36400
    },
    {
      "epoch": 4.877559213167403,
      "grad_norm": 0.18290041387081146,
      "learning_rate": 4.988625719255988e-06,
      "loss": 0.3371,
      "step": 36450
    },
    {
      "epoch": 4.884249966546233,
      "grad_norm": 0.281310498714447,
      "learning_rate": 4.72099558410277e-06,
      "loss": 0.3504,
      "step": 36500
    },
    {
      "epoch": 4.890940719925063,
      "grad_norm": 0.3569011092185974,
      "learning_rate": 4.453365448949552e-06,
      "loss": 0.3601,
      "step": 36550
    },
    {
      "epoch": 4.897631473303894,
      "grad_norm": 0.32788074016571045,
      "learning_rate": 4.185735313796334e-06,
      "loss": 0.3607,
      "step": 36600
    },
    {
      "epoch": 4.904322226682725,
      "grad_norm": 0.33913418650627136,
      "learning_rate": 3.9181051786431154e-06,
      "loss": 0.3328,
      "step": 36650
    },
    {
      "epoch": 4.911012980061555,
      "grad_norm": 0.3217945396900177,
      "learning_rate": 3.650475043489897e-06,
      "loss": 0.3347,
      "step": 36700
    },
    {
      "epoch": 4.917703733440385,
      "grad_norm": 0.24013996124267578,
      "learning_rate": 3.382844908336679e-06,
      "loss": 0.3364,
      "step": 36750
    },
    {
      "epoch": 4.9243944868192155,
      "grad_norm": 0.21977956593036652,
      "learning_rate": 3.1152147731834605e-06,
      "loss": 0.3335,
      "step": 36800
    },
    {
      "epoch": 4.931085240198046,
      "grad_norm": 0.14824765920639038,
      "learning_rate": 2.847584638030242e-06,
      "loss": 0.3703,
      "step": 36850
    },
    {
      "epoch": 4.937775993576877,
      "grad_norm": 0.301779568195343,
      "learning_rate": 2.579954502877024e-06,
      "loss": 0.3268,
      "step": 36900
    },
    {
      "epoch": 4.944466746955707,
      "grad_norm": 0.3603159189224243,
      "learning_rate": 2.3123243677238056e-06,
      "loss": 0.3403,
      "step": 36950
    },
    {
      "epoch": 4.951157500334538,
      "grad_norm": 0.44072526693344116,
      "learning_rate": 2.0446942325705876e-06,
      "loss": 0.3369,
      "step": 37000
    },
    {
      "epoch": 4.957848253713368,
      "grad_norm": 0.28498169779777527,
      "learning_rate": 1.7770640974173691e-06,
      "loss": 0.333,
      "step": 37050
    },
    {
      "epoch": 4.964539007092198,
      "grad_norm": 0.32711344957351685,
      "learning_rate": 1.509433962264151e-06,
      "loss": 0.3379,
      "step": 37100
    },
    {
      "epoch": 4.971229760471029,
      "grad_norm": 0.7273861169815063,
      "learning_rate": 1.2418038271109329e-06,
      "loss": 0.3802,
      "step": 37150
    },
    {
      "epoch": 4.97792051384986,
      "grad_norm": 0.30118900537490845,
      "learning_rate": 9.741736919577144e-07,
      "loss": 0.347,
      "step": 37200
    },
    {
      "epoch": 4.98461126722869,
      "grad_norm": 0.2663072645664215,
      "learning_rate": 7.065435568044962e-07,
      "loss": 0.3539,
      "step": 37250
    },
    {
      "epoch": 4.99130202060752,
      "grad_norm": 0.5143397450447083,
      "learning_rate": 4.3891342165127794e-07,
      "loss": 0.3293,
      "step": 37300
    },
    {
      "epoch": 4.997992773986351,
      "grad_norm": 0.7291901111602783,
      "learning_rate": 1.7663588920112404e-07,
      "loss": 0.3336,
      "step": 37350
    }
  ],
  "logging_steps": 50,
  "max_steps": 37365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5312491654145280.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
