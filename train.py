# -*- coding: utf-8 -*-
"""Train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17SY4I5fp4wMEntkmDOGuDN01ZLTi2B7P
"""

import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, Trainer, pipeline
from peft import LoraConfig
from datasets import Dataset
import datasets
from trl import SFTTrainer, PPOTrainer

from tqdm import tqdm
#load model name
# model_name = "qwen/Qwen2.5-0.5B"
import argparse

argparser = argparse.ArgumentParser()
argparser.add_argument('--model_name', type=str, default='qwen/Qwen2.5-1.5B')
argparser.add_argument('--dataset', type=str, default='gsm8k')
args = argparser.parse_args()

model_name = args.model_name
# model_name = "bkai-foundation-models/vietnamese-llama2-7b-120GB"

based_model = AutoModelForCausalLM.from_pretrained(model_name,
  # quantization_config=quant_config,
  torch_dtype=torch.float16,
  device_map={"":0}
)

tokenizer = AutoTokenizer.from_pretrained(model_name)

peft_params = LoraConfig(
    r=128,
    lora_alpha=16,
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM",
)
if args.dataset == 'gsm8k':
    dataset = datasets.load_dataset("gsm8k", "main")

train_dataset, test_dataset = dataset['train'], dataset['test']


def preprocess_function(examples):
    inputs = [f"<|im_start|>user\n{prompt}<|im_end|>\n" for prompt in examples["question"]]
    # print(inputs[0])
    targets = [f"<|im_start|>assistant\n{completion}<|im_end|>\n" for completion in examples["answer"]]
    # print(targets[0])
    # model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding="max_length")
    model_inputs = tokenizer(inputs,
                            #  max_length=512, padding = True
                             )
    # labels = tokenizer(targets, max_length=512, truncation=True, padding = True)
    labels = tokenizer(targets,
                      #  max_length=512, padding = True
                       )
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)

tokenized_eval_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=gsm8k_test.column_names)

# %cd /content/drive/MyDrive/qwen

training_params = TrainingArguments(
    output_dir="./results",
    num_train_epochs=5,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=1,
    logging_steps=50,
    learning_rate=2e-4,
    logging_dir="./logs",
    save_strategy="epoch",
    fp16=True,
    optim="adamw_torch"
)

trainer = SFTTrainer(
    model=based_model,
    train_dataset=tokenized_dataset,
    eval_dataset=tokenized_eval_dataset,
    peft_config=peft_params,
    max_seq_length=None,
    args=training_params,
    packing=False,
)

#turn off wandb
import os
os.environ["WANDB_DISABLED"] = "true"

# trainer.train() #This is 0.5B

trainer.train() #This is 1.5B

based_model

### in ra output tu 1 prompt
prompt = '''<|im_start|>user
Jen buys and sells candy bars. She buys candy bars for 80 cents each and sells them for a dollar each. If she buys 50 candy bars and sells 48 of them, how much profit does she make in cents?<|im_end|>

<|im_start|>assistant'''
output = based_model.generate(tokenizer(prompt, return_tensors='pt').input_ids.to('cuda'), early_stopping=True)


print(tokenizer.decode(output[0]))